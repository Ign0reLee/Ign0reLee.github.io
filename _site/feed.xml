<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-07-23T17:13:41+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Jeyoung Lee’s Blog</title><subtitle>A day without laughter is a day wasted.</subtitle><author><name>Jeyoung Lee</name></author><entry><title type="html">RAY with RAPIDS Part-1</title><link href="http://localhost:4000/RAY_with_RAPIDS_Part_1.html" rel="alternate" type="text/html" title="RAY with RAPIDS Part-1" /><published>2025-01-12T00:00:00+09:00</published><updated>2025-01-12T00:00:00+09:00</updated><id>http://localhost:4000/RAY_with_RAPIDS_Part_1</id><content type="html" xml:base="http://localhost:4000/RAY_with_RAPIDS_Part_1.html"><![CDATA[<h2 id="0-시작하며">0. 시작하며</h2>
<hr />

<p>안녕하세요, 가톨릭 대학교 박사 과정 이제영입니다.</p>

<p>혹시 여러분들은 NVIDIA Tech Blog를 구독 하시나요? 저는 NVIDIA에서 Ambassador로 활동하고 있기 때문에, NVIDIA Tech Blog를 자주 보는 편입니다.</p>

<p>그 중 제가 주로 활동하고 있는 GPU-based Data Science와 관련한 글들은 실습까지 꼭 진행해 보는데요, 지난 2024년 12월 20일 RAPIDS를 RAY와 함께 사용하는 좋은 글이 올라왔습니다.<a href="https://developer.nvidia.com/blog/accelerating-gpu-analytics-using-rapids-and-ray/" target="_blank">Accelerating GPU Analytics Using RAPIDS and RAY LINK</a></p>

<p>실은 저는 RAPIDS를 사용할때 RAY를 굉장히 많이 활용하고 있습니다.
로
주로 RAY를 사용한 Hyper Paramter Optimization을 자주 수행하는데요, RAY Tune을 RAPIDS와 함께 사용하면 굉장히 빠른 속도로 HPO를 수행할 수 있습니다.</p>

<p>따라서 오늘은 RAY와 RAPIDS를 사용한 Data Engineering Pipelines 실습과 XGBoost를 사용하여 Hyper Parameter Optimization까지 진행 해보려 합니다.</p>

<p>혹시 아직 RAPIDS를 사용하는데 익숙치 않거나 GPU-based Data Science/Engineering이 어려우신 분들은 기회가 된다면 제가 blog로 정리해두겠습니다.</p>

<h2 id="1-ray">1. RAY</h2>

<p><a href="https://www.ray.io/" target="_blank" title="Source: Official Ray Homepage">
    <img src="./assets/img/images/2025_01_12/RAY.png" width="656" height="400" layout="responsive" alt="RAY Logo" class="mb3" />
    <center> 
        &lt;Figure 1. RAY&gt;
    </center>
</a></p>

<p>RAY tune 라이브러리로 대표되는 RAY는 실은 다양한 라이브러리들이 묶여있는 하나의 platform입니다.</p>

<p>특히 RAY는 CPU/GPU를 활용한 병렬 처리 및 각종 연산 자원 분배, pipline 구성, 학습, 튜닝 등의 다양한 기능을 지원합니다.</p>

<p>이 중 오늘은 cuDF를 활용하여 데이터의 파이프라인을 구성하기 위해, RAY Core의 Actor를 활용합니다.</p>

<p>RAY core는 분산 어플리케이션을 구축하고 확장하기 위한 핵심 기본요소들을 제공하는 라이브러리입니다.</p>

<p>RAY Actor는 각 woker들이 데이터를 저장, 관리, 변형할 수 있도록 도와주는 클래스입니다.</p>

<p>이런 RAY Actor를 활용하여 GPU를 Management하고, 병렬 연산을 수행시킨다면 cuDF 라이브러리를 효과적으로 다룰 수 있게 됩니다.</p>

<p>한번 코드를 직접 볼까요?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@ray.remote</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">cuDFActor</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">-&gt;</span><span class="bp">None</span><span class="p">:</span>        
            <span class="bp">...</span>
      
    <span class="k">def</span> <span class="nf">read_parquet</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">cd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">cd</span><span class="p">.</span><span class="nf">read_parquet</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df</span>

<span class="c1"># Start 4 Workers 
</span><span class="n">pool_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">actor_pool</span> <span class="o">=</span> <span class="p">[</span><span class="n">cuDFActor</span><span class="p">.</span><span class="nf">remote</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">pool_size</span><span class="p">)]</span>
</code></pre></div></div>

<p>위의 코드는 간단한 Ray와 cuDF코드입니다.</p>

<p>RAY Actor는 파이썬의 데코레이터 형태로 선언할 수 있습니다.</p>

<p>또한 중요하게 봐야하는 부분이 몇가지가 있는데요, 우선 @ray.remote안의 num_gpus의 값입니다.</p>

<p>num_gpus는 사용가능한 gpu의 개수를 의미하는데요, 이 때 ray는 num_gpus를 소수의 형태로도 할당 할 수 있습니다.</p>

<p><strong>즉 만약 num_gpus=0.5로 할당한다면, ray는 actor를 처리할 때 GPU 리소스의 절반만 활용하여 작업하게 됩니다.</strong></p>

<p>다음으로 주의 깊게 봐야 하는 것은 Actor의 선언인데요. 을바로 actor_pool = [cuDFActor.remote() for i in range(pool_size)] 부분입니다.</p>

<p><strong>기본적으로 RAY Actor를 활용하여 작업을 수행할 땐 다음과 같은 순서로 진행 되게 됩니다.</strong></p>

<blockquote>
  <ol>
    <li>RAY Actor Class 정의</li>
    <li>RAY Actor Class 할당</li>
    <li>RAY Actor Class 실행</li>
  </ol>
</blockquote>

<p>따라서 현재는 이미 선언한 RAY Actor Class에 대하여 총 4개의 Worker가 작업하도록 할당하고 있는 것인데요.</p>

<p>만약 여러분들이 4개의 GPU가 있다면, RAY Actor는 한개의 Actor Class에 대해 한개의 GPU 전체 자원을 사용하여 작업할 것을 기대합니다.</p>

<p>그럼 만약에 어려분들이 4개의 GPU가 없다면 어떤일이 발생할까요? 이는 다음에 이야기하도록 하겠습니다.</p>

<h2 id="2-create-dataset">2. Create Dataset</h2>
<hr />

<p>그러면 본격적으로 Sample Data를 활용하여 RAY와 cuDF를 써보도록 할까요?</p>

<p>이를 위해 classification용 예시 데이터를 만들어 보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cupy</span> <span class="k">as</span> <span class="n">cp</span>
<span class="kn">import</span> <span class="n">cudf</span> <span class="k">as</span> <span class="n">cd</span>
<span class="kn">import</span> <span class="n">dask_cudf</span> <span class="k">as</span> <span class="n">dd</span>

<span class="kn">from</span> <span class="n">cuml.datasets.classification</span> <span class="kn">import</span> <span class="n">make_classification</span>


<span class="n">column_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="s">col_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">"</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="sh">"</span><span class="s">target</span><span class="sh">"</span><span class="p">]</span>
<span class="n">dtypes</span>       <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">column_names</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">float32</span><span class="sh">'</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="sh">'</span><span class="s">int8</span><span class="sh">'</span><span class="p">]))</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">137</span><span class="p">)</span>

<span class="n">df</span>   <span class="o">=</span> <span class="n">cd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">cp</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span> <span class="n">column_names</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="p">)</span>
<span class="n">df</span>   <span class="o">=</span> <span class="n">dd</span><span class="p">.</span><span class="nf">from_cudf</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">npartitions</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">os</span><span class="p">.</span><span class="nf">makedirs</span><span class="p">(</span><span class="sh">"</span><span class="s">./output</span><span class="sh">"</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">to_parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">./output/data</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p>실은 제가 분산 처리 혹은 병렬 처리를 한다면 주로 dask_cudf를 많이 사용합니다. 하지만 이번 단계에선 dask_cudf에 대한 이야기는 없을 예정입니다.
기회가 된다면 말씀드리면 좋지만, 결론적으로 <strong>현재 작업에서 dask_cudf와 RAY를 함께 사용하는 것은 썩 좋은 생각이 아닙니다.</strong></p>

<p>지금은 우선 현재 코드에대해 이야기 해보도록 하겠습니다. 우리는 예시를 위해 100개의 feature를 가지고 1000000개의 인스턴스를 가진 데이터를 생성했습니다. 그리고 DataFrame화 시키기 위해 각 feature별로 “col_숫자”의 형태로 이름을 달았습니다. 마지막으로 class를 총 두개로 간단한 이진 문제를 푸는 데이터를 생성했습니다.</p>

<p>마지막으로 이렇게 만든 데이터에 대해 dask_cudf를 활용하여 4개의 파티션으로 나누고 parquet 파일 형식으로 저장하였습니다. 이렇게 저장하게 되면 parquet 파일은 총 4개가 생성 될 것입니다. 한번 볼까요?</p>

<p><img src="./assets/img/images/2025_01_12/data_structure.png" width="656" height="400" layout="responsive" alt="Sample Data Structure" class="mb3" /></p>
<center> 
    &lt;Figure 2. Sample Data Structure&gt;
</center>

<p>이렇게 생성된 4개의 parquet 파일을 읽고, XGBoost를 활용하여 학습해볼 예정입니다.</p>

<p>자, 그럼 여기서 문제입니다. 만약 여러분들이 cuDF나 Pandas를 가지고 4개의 parquet파일을 읽어 오려면 어떻게 해야할 까요??</p>

<p>가장 간단한 방법은 <strong>각 파일 별로 read_parquet한 후 concat하는 것</strong>입니다.</p>

<p>물론 나쁘지 않은 방법이지만 <strong>하나의 파일이 크면 클 수록 시간이 증가</strong>할 것입니다.</p>

<p>그렇다면 두번째 방법은 무엇일까요? 바로 cuDF를 이용하여 한번에 읽어오는 것입니다.</p>

<p>cuDF의 read_parquet는 여러개의 parquet파일을 읽어 하나의 DataFrame으로 병합하는 것을 지원하고 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">cudf</span><span class="p">.</span><span class="nf">read_parquet</span><span class="p">(</span><span class="sh">'</span><span class="s">./output/data/*.parquet</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p>물론 첫번째 방법 보단 효율적이지만 근본적으로 순차적으로 읽어 온 후 병합한다는 사실은 변하지 않습니다.</p>

<p>그렇다면 어떻게 좀 더 효율적으로 읽어 올 수 있을까요??</p>

<p>가장 <strong>간단한 방법은 분산 처리하여 파일별로 별도로 읽어 올 수 있다면</strong> 효율적으로 읽어올 수 있을 것입니다.</p>

<p>하지만, <strong>cuDF는 기본적으로 단일 파티션, 하나의 GPU에서만 동작할 수 있는데 어떻게 하면 분산 처리할 수 있을까요??</strong></p>

<p>이럴 때 우리는 <strong>RAY를 이용하여 분산 처리를 수행할 수 있습니다.</strong></p>

<h2 id="3-read-dataset-with-ray">3. Read Dataset with RAY</h2>
<hr />

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">ray.util</span> <span class="kn">import</span> <span class="n">ActorPool</span>
<span class="nd">@ray.remote</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">cuDFActor</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="p">:</span><span class="nb">int</span> <span class="o">=</span> <span class="bp">None</span>
                <span class="p">)</span><span class="o">-&gt;</span><span class="bp">None</span><span class="p">:</span>
        <span class="bp">...</span>

<span class="c1"># Create actors
</span><span class="n">num_actors</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1"># Number of Actors
</span><span class="n">actors</span> <span class="o">=</span> <span class="p">[</span><span class="n">cuDFActor</span><span class="p">.</span><span class="nf">remote</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_actors</span><span class="p">)]</span> <span class="c1"># Remote Actors, Now We make remote gpus = 0.5, and use 1 T4 GPU so gpu run 2
</span><span class="n">pool</span>   <span class="o">=</span> <span class="nc">ActorPool</span><span class="p">(</span><span class="n">actors</span><span class="p">)</span> <span class="c1"># Make Acotr Pool Object
</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="p">.</span><span class="nf">map_unordered</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">actor</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="n">actor</span><span class="p">.</span><span class="n">read_parquet</span><span class="p">.</span><span class="nf">remote</span><span class="p">(</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">p</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">glob</span><span class="p">.</span><span class="nf">glob</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="sh">"</span><span class="s">./output/data</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">*</span><span class="sh">"</span><span class="p">))</span>
    <span class="p">)</span>

<span class="c1"># Finally, we can obtain a cuDF DataFrame using Ray.
</span><span class="n">results</span> <span class="o">=</span> <span class="n">cd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="nf">head</span><span class="p">())</span>
<span class="c1"># print(results[0].heaead())
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Read datasets Finished...</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p>간단합니다. 우리가 살펴본 actor를 사용하는 방법처럼 4개의 actor를 실행합니다. 그리고 연산을 도와줄 ActorPool을 사용합니다.</p>

<p>ActorPool은 Actor들에게 각종 Pool연산을 효율적으로 할 수 있도록 도와주는 모듈입니다.</p>

<p>우리는 그중 map_unodered() 매소드를 활용하여 각 데이터의 파일별로 actor한개에 할당하려고합니다. map_unodered()는 순서와 관계 없이 pool 연산을 진행하고 싶을 때 사용하는 메소드입니다.</p>

<p>현재 저는 2080 super 2대의 환경에서 진행하고 있으며, 각 gpu별로 0.4의 리소스를 가지고 4개의 actor가 2개의 GPU에서 작업하게 됩니다.</p>

<p>이경우 RAY는 자동적으로 최적화 하여 GPU에 할당 및 연산을 진행하며, 지금의 경우 두개의 GPU에 각각 0.4씩 총 4개의 Actor가 할당 될것입니다.</p>

<p><strong>즉 4개의 파일을 GPU 2개가 한번의 연산으로 읽어</strong>올 수 있습니다..!</p>

<p>잘 읽어 왔는지 볼까요??</p>

<p><img src="./assets/img/images/2025_01_12/results.png" width="656" height="400" layout="responsive" alt="Results" class="mb3" /></p>
<center> 
    &lt;Figure 3. Results&gt;
</center>

<p>제대로 읽어온 것을 확인할 수 있습니다.</p>

<p>다만, 현재 우리는 순서와 관계 없이 읽어오도록 코드를 작성했습니다.</p>

<p>따라서 현재 인스턴스는 우리의 예상과는 다르게 250000부터 시작하는 것을 확인할 수 있습니다.</p>

<p>우선 글이 길어지는 관계로 RAY와 RAPIDS는 다음에 Part-2 XGBoost HPO로 다시 돌아오도록 하겠습니다.</p>

<p>원본 코드는 조만간 공개하겠습니다.</p>

<p>읽어주셔서 감사합니다 :)</p>]]></content><author><name>Jeyoung Lee</name></author><category term="RAPIDS" /><category term="RAY" /><category term="cuDF" /><category term="cuML" /><category term="XGBoost" /><category term="GPU" /><category term="multiprocessing" /><summary type="html"><![CDATA[0. 시작하며]]></summary></entry><entry><title type="html">Understanding task units of CUDA</title><link href="http://localhost:4000/Understanding_task_units_of_CUDA.html" rel="alternate" type="text/html" title="Understanding task units of CUDA" /><published>2024-12-11T14:00:00+09:00</published><updated>2024-12-11T14:00:00+09:00</updated><id>http://localhost:4000/Understanding_task_units_of_CUDA</id><content type="html" xml:base="http://localhost:4000/Understanding_task_units_of_CUDA.html"><![CDATA[<h2 id="0-시작하며">0. 시작하며</h2>
<hr />

<p>안녕하세요, 가톨릭 대학교 박사 과정 이제영입니다.</p>

<p>오랫동안 blog를 방치하고 있었는데, 가끔은 제가 공부했던 것이나 생각나는 것을 정리해두면 좋을 것 같아 새로운 형태로 다시 시작하게 되었습니다.</p>

<p>오늘은 Cupy를 이용하여 CUDA Custom Kernel을 작성하는 연습을 진행하다가 CUDA에서 헷갈렸던 부분을 다시 정리해봅니다.</p>

<p>개인적으로 정리하는 것이니 제가 이렇게 이해했다 정도로 참고해주시면 감사하겠습니다.</p>

<h2 id="1-thread-block-grid와-gpu">1. Thread, Block, Grid와 GPU</h2>
<hr />

<p>CUDA를 사용한 GPU 프로그래밍시 <strong>thread</strong>와 <strong>block</strong>, <strong>grid</strong>에 대한 이야기는 항상 등장합니다.</p>

<p>CUDA를 배울땐, thread가 모여서 block, block이 모여서 grid 라고하며 보통 CUDA 프로그래밍에서 Grid는 작업을 구성하는 가장 상위 단위로, 하나의 GPU는 여러 Grid를 동시에 실행할 수 있습니다.</p>

<p>그리고 일반적으로 thread와 block를 내가 할당할수 있다는 것과 어떻게 할당 해야 하는지,</p>

<p>각 단위의 의미와 한번에 <strong>병렬 처리</strong> 하여 연산한다는 것 정도를 집고 주로 Kernel Function을 작성하는 예제로 넘어가게 됩니다.</p>

<p>제가 갑자기 헷갈렸던 것은 <strong>GPU</strong>의 <strong>스펙</strong>과 <strong>thread/block</strong>과의 관계였습니다.</p>

<p>제가 Ambassador로 활동하고 있는 NVIDIA DLI과정 중 Accelerating Data Engineering Pipelines Optimization 과정에선 Hardware System으로서의 Data Engineering Pipelines 파트가 있습니다.</p>

<p>이 파트에서 <strong>GPU</strong>의 <strong>CUDA Core</strong>와 <strong>Streaming Multiprocessor(SM)</strong>의 언급과 쉽게 설명하기 위해 <strong>정확하진 않지만, 쉽게 말하자면, 한번에 연산가능한 CUDA Core가 thread의 개수를 의미하는 것이고 SM이 Block의 개수를 의미하는 것이다.</strong>라고 강의자료에 되어있습니다.</p>

<p>그런데, <strong>실제로 Block개수와 Thread의 개수를 GPU에 작성되어있는 CORE개수와 SM개수만큼 할당하고 연산할 수 있는 것일까요??</strong></p>

<p>제가 간단하게 검색해보기론 이러한 부분에 대한 이야기가 자세히 나와있지 않은것 같아서 정리해보고자 합니다.</p>

<h2 id="2-간단한-예시-rtx-3090">2. 간단한 예시 RTX 3090</h2>
<hr />

<p>이에대해 파악하기 위해 우선 간단하고 유명한 GPU인 RTX 3090중 CUDA 프로그래밍 특히 이번 포스트에서 알아보고자 하는 부분을 이해하기 위한 스펙을 적어보도록하겠습니다.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">항목</th>
      <th style="text-align: center">세부내용</th>
      <th style="text-align: center">항목</th>
      <th style="text-align: center">세부내용</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">CUDA core 개수</td>
      <td style="text-align: center">8704개</td>
      <td style="text-align: center">블록당 최대 쓰레드 수의 곱</td>
      <td style="text-align: center">1024개</td>
    </tr>
    <tr>
      <td style="text-align: center">SM 개수</td>
      <td style="text-align: center">68개</td>
      <td style="text-align: center">워프 당 실행 쓰레드 수</td>
      <td style="text-align: center">32개</td>
    </tr>
    <tr>
      <td style="text-align: center">SM당 CUDA 코어 수</td>
      <td style="text-align: center">128개</td>
      <td style="text-align: center">SM당 최대 워프 수</td>
      <td style="text-align: center">64개</td>
    </tr>
    <tr>
      <td style="text-align: center">SM당 최대 쓰레드 수</td>
      <td style="text-align: center">2048개</td>
      <td style="text-align: center">SM당 최대 블록 수</td>
      <td style="text-align: center">32개</td>
    </tr>
  </tbody>
</table>

<center> 
table 1. RTX 3090 스펙 
</center>

<h2 id="3-gpu와-cuda-core">3. GPU와 CUDA core</h2>
<hr />

<p>일반적으로 <strong>GPU</strong>를 잘쓴다는 것은 무엇일까요? 여러가지 의미가 있겠지만, 보통 GPU를 잘 다룬다는 것은 Utilization은 최대한 100%로 유지하면서, task를 처리하는 것일 겁니다. 즉 <strong>GPU</strong>의 사용량은 최대로(효과적으로) 유지하면서 나의 작업을 빠르게 처리하는 것이 보통 GPU를 잘 다룬다는 것일 겁니다.</p>

<p>그리고 실은(어찌보면 당연한 것이겠지만) 우리가 할당할 수 있는 thread의 개수와 block의 개수는 <strong>GPU</strong>별로 다르며, 또한 한번에 연산가능한 숫자와 한 Kernel function이 할당 받을 수 있는 thread와 block의 개수도 <strong>GPU</strong>의 제원을 통해 어느정도 확인 가능 합니다.</p>

<p>따라서 우리는 우리가 사용하고자하는 <strong>GPU</strong>의 사양을 명확하게 알고, CUDA 프로그래밍을 시도해야겠습니다.</p>

<p>일단 가장 먼저 봐야하는 것은 당연하게도 CUDA core의 개수인데요, CUDA Core의 개수는 말 그대로 CUDA core의 총 개수를 의미하는 것이기 때문에, SM당 CUDA코어 수와 SM개수를 곱하는 것으로 구할 수 있습니다. 또한 기본적으론 CUDA core의 개수가 우리가 사용하고자 하는 <strong>GPU</strong>의 <strong>한번에 연산 가능한 thread의 총 개수</strong>라고 보면 될 것 같습니다 :)</p>

<p>여기서 한가지 의문이 드는데요, 한번에 연산 가능한 thread의 총 개수가 RTX 3090의 개수라고하면, 할당 가능한 총 쓰레드의 개수는 다를까요??</p>

<p>정답은 다르다입니다. 이를 위해서 확인 해봐야 하는 것은 SM당 최대 쓰레드 수인데요. <strong>GPU</strong>에서 쓰레드를 할당 한다는 것은, <strong>GPU</strong>를 사용해 한번에 연산한다는 것과는 다른 의미였습니다…</p>

<h2 id="4-thread-할당과-warp-연산">4. thread 할당과 warp 연산</h2>
<hr />

<p>그러면 한번에 연산 가능한 최대 개수가 8704개라는 것과 할당 가능한 thread의 개수가 차이가 나는 이유가 무엇일까요?? 이는 CUDA 코어와 쓰레드의 차이에 대해 이해 해야합니다.</p>

<p>그냥 쉽게 말하자면, <strong>CUDA 코어는 실제 연산을 수행하는 물리적 계산 장치</strong>이고, <strong>쓰레드는 작업을 나누기 위한 논리적 작업 단위</strong>이기 때문입니다.</p>

<p>어찌보면 모두가 알고 있는 것인데, 제대로 생각해본적이 없는 것 같습니다 :)</p>

<p>그렇다면 우리가 thread를 할당할 때 최대 몇개까지 할당할 수 있을까요??</p>

<p>정답은  $2048 * 68 = 139264 \; 개입니다. 그렇다면 왜 2048개의 thread까지 할당할 수 있을까요?? 이는 <strong>GPU</strong>에서의 warp연산과 스케줄링을 이해 해야합니다.</p>

<p>GPU에서 연산을 처리할 때, SM은 thread를 <strong>Warp(32개의 쓰레드 단위)</strong>로 묶어 실행합니다. SM은 한 번에 4개의 Warp를 병렬로 실행하며, 나머지 Warp는 대기 상태로 스케줄링됩니다.</p>

<p>이는 무슨 이야기냐면, SM은 쿠다 코어를 32개를 1개로 묶어 동시에 연산을 시키게 되는데요, RTX 3090은 SM 안에 쿠다 코어가 128개 씩 존재하니, 총 4개의 warp가 동시에 실행된다고 볼 수 있습니다.</p>

<p>마지막으로 SM당 할당 가능한 최대 warp의 숫자는 64개이므로 $64 * 32 = 2048 \; 개까지 할당 가능합니다.</p>

<h2 id="5-thread-할당과-block-할당">5. thread 할당과 block 할당</h2>
<hr />

<p>마지막으로 block에 대한 이야기인데요, 일반적으로 CUDA를 배운다고 하면, thread의 묶음을 block로 배우곤합니다.</p>

<p>물론 맞는 이야기입니다만, 오늘은 GPU에서 할당되는 연산과 엮어서 같이 볼 예정이므로, block당 thread의 최대개수와 SM당 block의 최대개수를 동시에 보면서 이야기 하겠습니다.</p>

<p>우선 기본적으로 block은 thread의 묶음이 맞습니다. 그래서 우리가 CUDA에서 맨처음 하는 것은 thread 개수와 block 개수를 정하게 되죠, <strong>기본적으로 CUDA는 받은 thread개수와 block개수를 SM이 최대한 공평하게 나누어 가지려고 시도</strong>합니다. 지금의 경우에는 68개의 <strong>SM이 최대한 공평하게</strong> 나누어 가지게되겠네요.</p>

<p>이 때, <strong>SM은 최대 32개</strong>의 block까지 할당 가능합니다. 또한 한 block당 thread의 최대 개수는 <strong>1024개</strong>까지입니다. 이는 1차원 thread가 기준으로 만약 2차원 이상이라면 각 차원의 곱이 해당 개수까지만 할당 가능합니다. 이 점을 주목하며 한번 생각 해보겠습니다.</p>

<p>만약 CUDA를 아래와 같이 코딩한다면 GPU에는 어떻게 할당이 될까요?</p>

<pre><code class="language-CPP">#include &lt;cuda_runtime.h&gt;
#include &lt;stdio.h&gt;

__global__ void printThreadInfo() {
    // Global ID 계산
    int globalIdx = blockIdx.x * blockDim.x + threadIdx.x;

    // 블록 ID와 쓰레드 ID 출력
    printf("BlockIdx.x: %d, ThreadIdx.x: %d, Global ID: %d\n", blockIdx.x, threadIdx.x, globalIdx);
}

int main(){
    int threadsPerBlock = 128;
    int numBlocks = 4;
    printThreadInfo&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;();
}
</code></pre>

<p>이경우 CUDA는 4개의 SM에 Block을 하나씩 할당하여 128개의 thread씩, 총 512개의 thread를 할당할 것입니다.</p>

<p>또한 RTX 3090기준으론 하나의 SM에 128개의 쿠다 코어가 존재하니 GPU는 한번에 512개의 값을 연산할 수 있을 것입니다.</p>

<p>그렇다면 남은 SM은 어떻게 될까요??</p>

<h2 id="6-block할당과-gpu성능">6. block할당과 GPU성능</h2>
<hr />

<p>이 때 CUDA 프로그래밍의 묘미가 발생하게 됩니다.</p>

<p>실은 위의 방식은 예제이기 때문에, 간단하게 이야기했지만, 현재의 상태에선 남은 <strong>64개의 SM은 활용하고 있지 않습니다.</strong></p>

<p>즉 우리가 효과적으로 GPU를 활용하기 위해선, 어떻게하면 SM을 효율적으로 사용할 수 있을지를 고민해야합니다.</p>

<p>지금의 경우, 각 SM은 한 번에 128개의 쓰레드만 처리할 수 있으므로 4개의 블록이 128개의 쓰레드를 포함할 때, GPU는 한 번에 512개의 쓰레드를 실행할 수 있습니다. 나머지 SM은 비활성 상태로 남게 됩니다.</p>

<p>또 SM의 개수는 68개이지만, block는 32개씩할당이 가능합니다. 연산만 놓고 봤을땐, 한번에 $128 * 68 = 8704\;번 계산되겠죠? 즉 GPU가 한번 딸깍하면 8704번 덧셈합니다.</p>

<p>우리는 이런 환경에서 어떻게 데이터를 잘게 쪼개어서 효과적으로 연산할지를 고민해야합니다.</p>

<p>여기서 추가적으로 고려 해봐야하는 것도 있습니다. 워프의 기본단위는 32입니다. 즉 하나의 thread는 32개씩 연산이됩니다. 32의 배수로 할당하는 것이 좋을까요?</p>

<p>혹은 128개의 thread를 68개의 block으로 할당할수도, 32개의 thread를 272개의 block에 할당할 수도 있을 것입니다. 두개의 차이는 무엇일까요? 둘다 RTX3090은 한번에 연산할 것입니다.</p>

<p>block의 개수는 68개의 SM에맞추어 배수로 설정하는 것이 좋을까요?? thread의 처리와 block의 처리중 어느것을 우선하여 처리할까요? 예를들면, 272개의 block에 128개의 thread를 할당하면 어떻게 될까요??</p>

<p>많은 질문이 새롭게 떠오르면 즐거운 밤입니다.</p>

<p>감사합니다.</p>]]></content><author><name>Jeyoung Lee</name></author><category term="CUDA" /><category term="GPU" /><category term="multiprocessing" /><summary type="html"><![CDATA[0. 시작하며]]></summary></entry><entry><title type="html">Attention And Transofrmer</title><link href="http://localhost:4000/Attention-And-Transformer.html" rel="alternate" type="text/html" title="Attention And Transofrmer" /><published>2021-03-23T14:00:00+09:00</published><updated>2021-03-23T14:00:00+09:00</updated><id>http://localhost:4000/Attention-And-Transformer</id><content type="html" xml:base="http://localhost:4000/Attention-And-Transformer.html"><![CDATA[<p><br />Attnetion Mechanism과 Trnasformer를 정리해보았습니다.</p>

<p><br />학교 발표용 자료로, 자세한 내용은 생략하고, 간단하게 정리했습니다.</p>

<p><br /></p>

<p><a href="https://www.nvidia.com/ko-kr/training/">참고 사이트1: Nvidia-DLI</a><br />
<a href="https://wikidocs.net/31379">참고 사이트2: Wikidocs</a><br />
<a href="http://cs231n.stanford.edu/">참고 사이트3: CS231N</a><br /></p>

<style>
.responsive-wrap iframe{ max-width: 100%;}
</style>

<div class="responsive-wrap">

<iframe src="https://catholicackr-my.sharepoint.com/:p:/g/personal/dlwpdud_catholic_ac_kr/ETyN47a79QpHsDDfaEBQTKUBPFK1412g9uMFzh7b9r4pCw?e=v46CRM&amp;action=embedview&amp;wdAr=1.7777777777777777" width="610px" height="367px" frameborder="0">포함된 <a target="_blank" href="https://office.com">Microsoft Office</a> 프레젠테이션, 제공: <a target="_blank" href="https://office.com/webapps">Office</a></iframe>

</div>]]></content><author><name>Jeyoung Lee</name></author><category term="Deep Learning" /><category term="Machine Learning" /><category term="Keras" /><category term="Tensorflow" /><category term="Attention" /><category term="Transformer" /><category term="PersonalStudy" /><summary type="html"><![CDATA[Attnetion Mechanism과 Trnasformer를 정리해보았습니다.]]></summary></entry><entry><title type="html">Tensorflow with Keras</title><link href="http://localhost:4000/Tensorflow-With-Keras.html" rel="alternate" type="text/html" title="Tensorflow with Keras" /><published>2020-12-18T22:00:00+09:00</published><updated>2020-12-18T22:00:00+09:00</updated><id>http://localhost:4000/Tensorflow-With-Keras</id><content type="html" xml:base="http://localhost:4000/Tensorflow-With-Keras.html"><![CDATA[<p><br /> Tensorflow2에서 Keras를 이용한 다양한 학습 방법들에 대해서 정리해보았습니다.</p>

<p><br /> Tensorflow2 Document를 따라 제작하였으며,  내용은 거의 같습니다.</p>

<p><a href="https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit">참고 사이트1</a><br />
<a href="https://www.tensorflow.org/guide/distributed_training?hl=ko">참고 사이트2</a><br />
<a href="https://github.com/Ign0reLee/Study_repository/tree/master/Keras">PPT의 코드</a></p>

<style>
.responsive-wrap iframe{ max-width: 100%;}
</style>

<div class="responsive-wrap">

<iframe src="https://catholicackr-my.sharepoint.com/:p:/g/personal/dlwpdud_catholic_ac_kr/ETbk37N6YRtKuTZeu5S53WEBiZL6zAazIIqxCTWiyqDJxw?e=8O1qsW&amp;action=embedview&amp;wdAr=1.7777777777777776" width="610px" height="367px" frameborder="0">포함된 <a target="_blank" href="https://office.com">Microsoft Office</a> 프레젠테이션, 제공: <a target="_blank" href="https://office.com/webapps">Office</a></iframe>

</div>]]></content><author><name>Jeyoung Lee</name></author><category term="Deep Learning" /><category term="Machine Learning" /><category term="Keras" /><category term="Tensorflow" /><category term="Distributed Training" /><category term="Sub-Classing" /><category term="PersonalStudy" /><summary type="html"><![CDATA[Tensorflow2에서 Keras를 이용한 다양한 학습 방법들에 대해서 정리해보았습니다.]]></summary></entry><entry><title type="html">03. Data Science With RAPIDS Cupy Part 02</title><link href="http://localhost:4000/Data-Science-With-RAPIDS-Cupy-Part02.html" rel="alternate" type="text/html" title="03. Data Science With RAPIDS Cupy Part 02" /><published>2020-08-19T22:00:00+09:00</published><updated>2020-08-19T22:00:00+09:00</updated><id>http://localhost:4000/Data-Science-With-RAPIDS-Cupy-Part02</id><content type="html" xml:base="http://localhost:4000/Data-Science-With-RAPIDS-Cupy-Part02.html"><![CDATA[<p><br /><br /></p>

<p>안녕하세요, 두번째 챕터 Cupy Part 02입니다.</p>

<p>오늘은 Cupy로 표현하는 선형대수학을 하도록 하겠습니다.</p>

<p>마찬가지로 코드위주로 작성할 예정이기 때문에 원본코드를 먼저 첨부하겠습니다.</p>

<p><a href="https://github.com/Ign0reLee/Data_Science_With_RAPIDS/blob/master/Chapter%2002.Cupy/Cupy%20Part-02.ipynb">원본코드 보러가기</a></p>

<p><br /><br /></p>

<h2 id="cupy와-선형대수">Cupy와 선형대수</h2>
<hr />

<p><br /><br /></p>

<p>선형 대수는 데이터 과학에서 기술과 개념을 뒷받침 해주는 분야입니다.</p>

<p>이번 챕터에서는 Cupy를 이용한 선형 대수 표현을 배우겠습니다.</p>

<p>실은 Cupy에서 이미 대부분의 선형대수의 개념을 함수로 만들어 놓았습니다.</p>

<p>그래도 아직 익수하지 못한 분들을 위해, 그리고 처음 보는 분들을 위해 선형 대수 부분을 넣어두었습니다.</p>

<p>따라서 앞서 배운 기초 부분과 많이 유사할 예정이며, 사용에 익숙하신 분들이라면 넘어가셔도 관계 없습니다.</p>

<p>자 그럼 시작하겠습니다.</p>

<p>주피터 노트북 환경에서, 쉘별로 확인해보도록 하겠습니다.</p>

<p><br /><br /></p>

<h2 id="import-하기">Import 하기</h2>
<hr />
<p><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kn">import</span> <span class="n">cupy</span> <span class="k">as</span> <span class="n">cp</span>
  <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<p>이번 칼럼에선 항상 numpy와 cupy를 임포트 해옵니다.</p>

<p>다만, 이번 챕터에서는 시간에 대한 부분은 빠져있습니다.</p>

<p>함수 사용에 관해 배울땐, 시간을 고려할 필요가 없기 때문입니다.</p>

<p><br /><br /></p>

<h2 id="21-벡터">2.1 벡터</h2>
<hr />
<p><br /></p>

<h3 id="210-벡터의-개념">2.1.0 벡터의 개념</h3>
<hr />

<p>벡터와 스칼라는 수학을 공부해본 사람이라면 많이 보았을 개념일 것입니다.</p>

<p>저는 수학과가 아니여서 그런지 벡터는 간단하게 방향이 있는 값 정도로 이해하고 있습니다.</p>

<p>참고하고 있는 모 책에서는 <strong><em>어떤 유한한 차원의 공간에 존재하는 점들</em></strong> 이라고 설명합니다.</p>

<p>대부분의 숫자는 벡터로 표현 가능합니다.</p>

<p>그리고 앞으로 많은 경우 이 벡터로 계산, 표현 할 예정입니다.</p>

<p>그러므로 벡터 사용에 익숙해 지는 것이 좋습니다.
<br /><br /></p>

<h3 id="211-벡터의-표현">2.1.1 벡터의 표현</h3>
<hr />

<p>벡터를 가장 간단하게 표현하는 방법은 Python의 list로 표현하는 방법입니다.</p>

<p>하지만 저희는 Cupy와 Numpy로 이해할 예정이기 때문에 array로 표현할 예정입니다.</p>

<p>list와 크게 다르지 않기 때문에 코드로 바로 확인해보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">numpy_vector</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">])</span>
<span class="n">cupy_vector</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">])</span>
</code></pre></div></div>

<p>저희는 앞서 cupy의 기초 파트에서 cupy array의 사용법에 대해서 익혔습니다.</p>

<p>기본적으론, numpy array와 같은 방법으로 사용하시면 됩니다.</p>

<p>다만 cupy의 경우 데이터가 GPU 메모리에 올라갑니다.</p>

<p>사진으로 확인해보겠습니다.</p>

<p><img src="./assets/img/images/RAPIDS/Cupy-02/GPU-MEMORY.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<br /><br /></p>

<h3 id="212-벡터의-덧셈">2.1.2 벡터의 덧셈</h3>
<hr />

<p>벡터의 덧셈에 대해 알아보겠습니다.</p>

<p>벡터끼리 더한다는 것은, 각 벡터상에서 같은 위치에 있는 성분끼리 더한다는 의미입니다.</p>

<p><img src="./assets/img/images/RAPIDS/Cupy-02/Vector-add.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<br /></p>

<p>Numpy와 Cupy 모두 add라는 함수로 구현되어 있습니다.</p>

<p>그림으로 보았던 예시를 코드로 실험해보겠습니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="213-벡터의-뺄셈">2.1.3 벡터의 뺄셈</h3>
<hr />

<p>벡터의 뺄셈도 덧셈과 마찬가지로 성분별로 진행합니다.</p>

<p>Numpy와 Cupy 모두 subtract라는 함수로 구현되어 있습니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="214-벡터와-스칼라곱">2.1.4 벡터와 스칼라곱</h3>
<hr />

<p>벡터와 스칼라곱은 벡터의 각 원소에 스칼라를 곱하는 것으로 표현합니다.</p>

<p>이는 multiply 함수로 표현할 수 있습니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">scalar</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">multiply</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span>  <span class="n">scalar</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">scalar</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">multiply</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="n">scalar</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="215-벡터의-내적">2.1.5 벡터의 내적</h3>
<hr />

<p>백터의 내적은 각 요소별로 곱한 후 더한 값을 의미합니다.</p>

<p>numpy와 cupy에선 dot이라는 함수로 구현되어 있습니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="216-벡터의-요소별-제곱">2.1.6 벡터의 요소별 제곱</h3>
<hr />

<p>벡터의 요소별 제곱은 square라는 함수로 구현되어 있습니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="217-벡터의-요소별-루트">2.1.7 벡터의 요소별 루트</h3>
<hr />

<p>벡터의 요소별 루트는 sqrt라는 함수로 구현되어 있습니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="218-벡터의-거리">2.1.8 벡터의 거리</h3>
<hr />

<p>이제 앞서 배운 개념들을 이용해 간단하게 벡터간 거리 연산을 진행할 수 있습니다.</p>

<p>거리에도 여러가지 개념이 존재하지만, 지금은 가장 일반적이라고 할 수 있는 유클리디언 거리를 측정해보도록 하겠습니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>

<span class="n">sub</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)</span>
<span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>
<span class="n">sums</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">square</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">sums</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>

<span class="n">sub</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)</span>
<span class="n">square</span><span class="o">=</span>  <span class="n">cp</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>
<span class="n">dot</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">square</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">dot</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="219-벡터의-거리에-대한-다양한-표현">2.1.9 벡터의 거리에 대한 다양한 표현</h3>
<hr />

<p>그런데, 위의 표현은 뭔가 간결해보이지 않습니다.</p>

<p>실은 같은 코드여도 여러가지 방식으로 표현할 수 있습니다.</p>

<p>지금부터 좀 더 간결해지기 위해 여러가지로 코드를 바꿔 보겠습니다.</p>

<p>당장 cupy를 사용하지 못하는 분들을 기준으로 하기 위해 numpy코드를 기준으로 해보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">))))</span>

<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /></p>

<p>같은 코드인데, 한줄로 표현 가능합니다.</p>

<p>뭐가 막 많아 보이지는 않지만 한 줄로 표현되어 있기에, 더 복잡해 보이기도 합니다.</p>

<p>이를 해결하기 위해 square sum부분을 dot으로 바꿔보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /></p>

<p>조금 나아진 것 같기도한데, 같은 코드를 두번 실행 시켜야하는 점이 걸립니다.</p>

<p>또한, 그 부분 때문에 더 복잡해 보이기도 합니다.</p>

<p>따라서 이부분은 나눠서 표현하겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>


<span class="n">sub</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">sub</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /></p>

<p>조금 더 나아졌지만, 여전히 sub가 두번 들어가는 것이 뭔가 마음에 들지 않습니다.</p>

<p>이를 함수로 표현하면 좀 더 나아질 수도 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">distance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">sum_of_square</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">)))</span>

<span class="n">vector1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">vector2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="nf">distance</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /></p>

<p>어떤가요? 조금 간결해졌나요?</p>

<p>이 방법 외에도 다양하게 표현할 수 있지만, 우선은 이정도로 넘어가도록 하겠습니다.</p>

<p>여러분들도 다양한 방법으로 거리를 표현해보시길 바라겠습니다.
<br /><br /></p>

<h2 id="22-행렬">2.2 행렬</h2>
<hr />
<p><br /></p>

<h3 id="220-행렬의-개념">2.2.0 행렬의 개념</h3>
<hr />

<p>행렬은 보통 2차원 이상의 차원으로 구성되어 있는 숫자의 집합을 의미합니다.</p>

<p>차원에 따라 2차원 행렬, 3차원 행렬, 다차원 행렬등으로 말하기도 합니다.</p>

<p>행렬은 보통 list의 list등으로 표현합니다.</p>

<p>즉, 2차원 list, 3차원 list등으로 작성함으로 표현할 수 있습니다.</p>

<p>당연하겠지만, numpy와 cupy에선 array를 활용하여 표현할 수도 있습니다.
<br /><br /></p>

<h3 id="221-행렬의-표현">2.2.1 행렬의 표현</h3>
<hr />

<p>행렬 파트를 공부할 때는 random.rand함수를 사용하도록 하겠습니다.</p>

<p>random은 행렬의 원소에 random한 실수 값을 주고 싶을 때 사용하는 메소드입니다.</p>

<p>그 중 rand함수는, 원하는 shape의 랜덤한 array를 생성해줍니다.</p>

<p>이때 값은 0에서 1사이입니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">B</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="222-행렬의-shape">2.2.2 행렬의 Shape</h3>
<hr />

<p>행렬은 n개의 행과 k개의 열로 구성되어 있습니다.</p>

<p>이 때, n과 k는 shape라는 함수로 구할 수 있습니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</code></pre></div></div>
<p>또한 numpy ndarray에 내장되어 있는 shape라는 함수를 사용해서도 구할 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">B</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</code></pre></div></div>
<p>cupy에서는 shape함수를 직접 제공하지 않습니다.</p>

<p>cupy ndarray의 shape를 사용하여 구할 수 있습니다.
<br /><br /></p>

<h3 id="223-단위-행렬">2.2.3 단위 행렬</h3>
<hr />

<p>기본적으로 단위 행렬이란, 대각선에 해당하는 성분은 1, 나머지는 0에 해당하는 n차 정사각 행렬을 의미합니다.</p>

<p>numpy와 cupy에서는 eye라는 함수로 제공되어 있습니다.</p>

<p>이 때, 굳이 정사각 행렬로 선언하지 않아도 관계 없습니다.</p>

<p>단, 이런 경우 (0,0)지점 부터 대각 성분만 1이고, 나머지는 전부 0입니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">B</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="224-행렬-덧셈">2.2.4 행렬 덧셈</h3>
<hr />

<p>행렬 덧셈은 벡터간의 덧셈과 유사합니다.</p>

<p>보통 요소별 덧셈을 의미합니다.</p>

<p>또한 제공되는 함수도 같습니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">A</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">A</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">B</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Result </span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">A</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">A</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">B</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Result </span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="225-행렬-곱셈">2.2.5 행렬 곱셈</h3>
<hr />

<p>행렬 곱셈은 행렬간 이항 연산을 의미합니다.</p>

<p>Numpy와 Cupy에서는 matmul이라는 함수로 제공합니다.</p>

<p><strong>Numpy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">A</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">A</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">B</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Result </span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Cupy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">A</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">A</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">B</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Result </span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>
<p><br /><br /></p>

<h3 id="마무리">마무리</h3>
<hr />
<p><br /></p>

<p>이것으로 cupy파트는 마치도록 하겠습니다.</p>

<p>당연하겠지만 모든 부분을 설명하진 않았습니다.</p>

<p>선형 대수학 부분도, cupy부분도 마찬가지입니다.</p>

<p>더 배우고 싶으시다면, cupy나 numpy의 공식 document를 참고하시길 바라겠습니다.</p>

<p>또한 질문 및 이야기는 언제든지 부탁드리겠습니다.</p>

<p>질문은 제가 활동하고 있는 사이트 Devstu에서 부탁드리겠습니다.</p>

<p><a href="https://devstu.co.kr">질문 하러 가기</a></p>

<p><a href="https://numpy.org/doc/">Numpy Document</a></p>

<p><a href="https://docs.cupy.dev/en/stable/">Cupy Document</a></p>]]></content><author><name>Jeyoung Lee</name></author><category term="RAPIDS" /><category term="Python" /><category term="Machine Learning" /><category term="DataScience" /><category term="Cupy" /><category term="cupy" /><category term="Data" /><category term="Data Science" /><summary type="html"><![CDATA[안녕하세요, 두번째 챕터 Cupy Part 02입니다.]]></summary></entry><entry><title type="html">02. Data Science With RAPIDS Cupy Part 01</title><link href="http://localhost:4000/Data-Science-With-RAPIDS-Cupy-Part01.html" rel="alternate" type="text/html" title="02. Data Science With RAPIDS Cupy Part 01" /><published>2020-08-09T22:00:00+09:00</published><updated>2020-08-09T22:00:00+09:00</updated><id>http://localhost:4000/Data-Science-With-RAPIDS-Cupy-Part01</id><content type="html" xml:base="http://localhost:4000/Data-Science-With-RAPIDS-Cupy-Part01.html"><![CDATA[<p><br /><br /></p>

<p>안녕하세요, 두번째 챕터 Cupy Part 01입니다.</p>

<p>오늘은 Cupy의 기초부터 시작하도록 하겠습니다.</p>

<p>그리고 코드위주로 작성할 예정이기 때문에 원본코드를 먼저 첨부하겠습니다.</p>

<p><a href="https://github.com/Ign0reLee/Data_Science_With_RAPIDS/blob/master/Chapter%2002.Cupy/Cupy%20Part-01.ipynb">원본코드 보러가기</a></p>

<p><br /><br /></p>

<h2 id="cupy">Cupy?</h2>
<hr />

<p><br /><br /></p>

<p>Cupy란 무엇일까요?</p>

<p>대부분의 사람들의 경우 python에서 수학적인 계산을 할 때 Numpy를 많이 사용할 것이라고 생각합니다.</p>

<p>Numpy는 훌륭하고, 빠르고, 편하고, 좋은 라이브러리입니다.</p>

<p>하지만 CPU에서 돌아간다는 점 때문에 대규모 작업을 처리할 때 작업시간이 조금 부담스러울 때가 있습니다.</p>

<p>Cupy란, Python에서 NVIDIA CUDA를 사용한 가속화 컴퓨팅을 제공하는 오픈소스 라이브러리입니다.</p>

<p>Cupy는 Numpy를 뛰어 넘는 속도를 보여주다고합니다.</p>

<p>심지어, 자체 테스트에선 연산이 100배 이상 차이나는 경우도 있었다고 합니다.</p>

<p>RAPIDS에서 제공하는 자체 Bechmark 기사를 같이 첨부하겠습니다.</p>

<p><a href="https://medium.com/rapids-ai/single-gpu-cupy-speedups-ea99cbbb0cbb">Single-GPU Cupy Speedups</a></p>

<p>그렇다면 이런 Cupy는 어떻게 사용하는 걸까요?</p>

<p>주피터 노트북 환경에서, 쉘별로 확인해보도록 하겠습니다.</p>

<p><br /><br /></p>

<h2 id="import-하기">Import 하기</h2>
<hr />
<p><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kn">import</span> <span class="n">cupy</span> <span class="k">as</span> <span class="n">cp</span>
  <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<p>이번 과정에서는 항상 Numpy와 Cupy 모두를 Import 할 예정입니다.</p>

<p>실제 환경에서는 Numpy를 Cupy로 바꾸는 것 만으로 대부분의 코드가 포팅 가능하게 됩니다.</p>

<p>왜냐하면 Numpy와 Cupy는 Method가 동일하기 때문입니다.</p>

<p>하지만 실제론 조금 다른 부분도 있습니다. 중요한 부분은 이번 챕터에서 보고 넘어가도록 하겠습니다.</p>

<p><br /><br /></p>

<h2 id="simple-test-code">Simple Test Code</h2>
<hr />
<p><br />
  간단한 코드를 통해 사용법을 보도록하겠습니다.</p>

<p>먼저 Numpy 버전 코드입니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="o">%%</span><span class="n">time</span>

  <span class="n">x_num</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="sh">"</span><span class="s">f</span><span class="sh">"</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">X : </span><span class="sh">"</span><span class="p">,</span> <span class="n">x_num</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">X sum : </span><span class="sh">"</span><span class="p">,</span> <span class="n">x_num</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

  <span class="err">!</span><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span>
</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/CPUTest.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
  <br /><br /></p>

<p>다음은 Cupy 버전 코드입니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="o">%%</span><span class="n">time</span>

  <span class="n">x_cp</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">X : </span><span class="sh">"</span> <span class="p">,</span> <span class="n">x_cp</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">X sum : </span><span class="sh">"</span><span class="p">,</span> <span class="n">x_cp</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

  <span class="err">!</span><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span>
</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/GPUTest.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
  지난번에 보았던 설치 부분에서도 봤던 코드와 유사합니다.</p>

<p>결과 출력된 화면을 보면, GPU메모리가 올라간게 보이시나요?</p>

<p>GPU에 Array가 올라갔음을 알 수 있습니다.</p>

<p><br /><br /></p>

<h2 id="time">Time</h2>
<hr />
<p><br />
  그런데 한가지 이상한 점이 있습니다.</p>

<p>Numpy보다 빠르다고 이야기를 했는데, 위의 코드에서는 Numpy가 Cupy보다 동작 시간이 더 짧음을 볼 수 있습니다.</p>

<p>어째서 Numpy의 동작 시간이 더 빨랐을까요?</p>

<p>지금의 경우에는 연산량이 작기 때문입니다.</p>

<p>무슨 이야기냐면, GPU는 항상 CPU보다 빠른것이 아닙니다.</p>

<p>다음과 같은 상황에서는 CPU가 GPU보다 빠른 성능을 낼 수도 있습니다.</p>

<ol>
  <li>계산량이 충분하지 않은 경우</li>
  <li>잘못된 구조로 GPU 아키텍쳐를 만들었을 경우</li>
  <li>(쉘 동작 시간에서는)처음 호출하는 경우</li>
</ol>

<p><br /></p>

<p>지금의 경우 3번과 1번에 해당하는 상황인 것 같습니다.</p>

<p>자 그러면 실제로 연산량이 많을수록 Cupy가 동작시간이 더 짧은지 코드로 확인해보겠습니다.</p>

<h2 id="computing-time-test">Computing Time Test</h2>
<hr />
<p><br /></p>

<p>지금 부터 간단하게 연산 시간 테스트를 해보겠습니다.</p>

<p>랜덤하게 생성한 N * N 크기의 행렬을 두개 만든 후, 내적을 실행해보겠습니다.</p>

<p>그리고 N의 크기를 증가 시켜가면서 속도를 테스트 해 볼 예정입니다.</p>

<p>직접 해보셔도 좋고, 결과만 보고 가셔도 괜찮습니다.</p>

<p><br /><br /></p>

<h3 id="case-1-n100">Case 1. n=100</h3>
<hr />
<p><strong>numpy</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
  <span class="o">%%</span><span class="n">time</span>

  <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>

</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/case1_cpu.png" width="656" height="50" layout="responsive" alt="" class="mb3" />
  <br />
  <strong>cupy</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
  <span class="o">%%</span><span class="n">time</span>

  <span class="n">a</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>

</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/case1_gpu.png" width="656" height="50" layout="responsive" alt="" class="mb3" />
  <br /><br /></p>

<h3 id="case-2-n1000">Case 2. n=1000</h3>
<hr />
<p><strong>numpy</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
  <span class="o">%%</span><span class="n">time</span>

  <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>

</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/case2_cpu.png" width="656" height="50" layout="responsive" alt="" class="mb3" />
  <br />
  <strong>cupy</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
  <span class="o">%%</span><span class="n">time</span>

  <span class="n">a</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
  
</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/case2_gpu.png" width="656" height="50" layout="responsive" alt="" class="mb3" />
  <br /><br /></p>

<h3 id="case-3-n10000">Case 3. n=10000</h3>
<hr />
<p><strong>numpy</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
  <span class="o">%%</span><span class="n">time</span>

  <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>

</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/case3_cpu.png" width="656" height="50" layout="responsive" alt="" class="mb3" />
  <br />
  <strong>cupy</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
  <span class="o">%%</span><span class="n">time</span>

  <span class="n">a</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
  
</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/case3_gpu.png" width="656" height="50" layout="responsive" alt="" class="mb3" />
  <br /></p>

<p>확실히 연산량이 늘어나면 늘어날수록 Numpy에 비해 Cupy가 훨씬 빠른 속도를 냄을 알 수 있습니다.</p>

<p>반면 n이 작을땐, Numpy가 속도가 더 빠른걸 볼 수 있습니다.</p>

<p><br /><br /></p>

<h2 id="cupy-data-type">Cupy Data Type</h2>
<hr />
<p><br /></p>

<p>처음 Cupy 매서드와 Numpy의 매서드가 거의 동일하다고 말씀 드렸습니다.</p>

<p>그렇다면 데이터 타입도 같을까요?</p>

<p>한번 확인해보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">Num_array</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">Num_array</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="nf">type</span><span class="p">(</span><span class="n">Num_array</span><span class="p">))</span>
</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/ndarray.png" width="150" height="25" layout="responsive" alt="" class="mb3" />
  <br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">Cupy_array</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">Cupy_array</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="nf">type</span><span class="p">(</span><span class="n">Cupy_array</span><span class="p">))</span>
</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/cudarray.png" width="150" height="25" layout="responsive" alt="" class="mb3" />
  둘이 데이터 타입이 조금 다름을 알 수 있습니다.</p>

<p>ndarray이긴 하나, Numpy의 ndarray와 cuda의 core에 올라가있는 cupy의 ndarray입니다.</p>

<p><br /><br /></p>

<h2 id="get">.get()</h2>
<hr />
<p><br /></p>

<p>그렇다면, cupy ndarray를 numpy ndarray타입으로 바꿀 수는 없을까요?</p>

<p>밑에 추가로 바꾸는 방법이 나오지만, 우선 .get()은 자주 사용할 예정임으로 따로 만들었습니다.</p>

<p>cupy array뒤에 .get()을 붙임으로 numpy ndarray로 만들 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">cpu_array</span> <span class="o">=</span> <span class="n">Cupy_array</span><span class="p">.</span><span class="nf">get</span><span class="p">()</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">cpu_array</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="nf">type</span><span class="p">(</span><span class="n">cpu_array</span><span class="p">))</span>
</code></pre></div></div>
<p><img src="./assets/img/images/RAPIDS/Cupy-01/cuda_to_ndarray.png" width="150" height="25" layout="responsive" alt="" class="mb3" /></p>

<p><br /><br /></p>

<h2 id="cupy-method">Cupy Method</h2>
<hr />
<p><br /></p>

<p>마지막으로 앞으로 자주 쓰일 매서드를 몇가지만 살펴보도록 하겠습니다.</p>

<p>Numpy 사용이 익숙하신 분들은 이 부분은 넘어가셔도 관계 없습니다.</p>

<p>또한 제대로 이해하시려면 documentation을 참고하시기 바랍니다.</p>

<p>지금은 쉽게 사용하기 위해 꼭 필요한 부분만 적어 넣었습니다.</p>

<p><a href="https://docs.cupy.dev/en/stable/">cupy documentation</a></p>

<p>실습 코드와 결과는 원본 코드를 참고해주시길 바라겠습니다.</p>

<p><br /><br /></p>

<h3 id="cupyarrayarg">cupy.array(arg)</h3>
<hr />
<p>cupy ndarray를 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupyarangestrat-stopnone-step1-dtypenone">cupy.arange(strat, stop=None, step=1, dtype=None)</h3>
<hr />
<p>시작부터 끝지점까지 step 간격을 가진 cupy ndarray를 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupyemptyshape-dtype">cupy.empty(shape, dtype)</h3>
<hr />
<p>초기화한 cupy ndarray를 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupyonesshape-dtype">cupy.ones(shape, dtype)</h3>
<hr />
<p>1로 초기화한 cupy ndarray를 반환합니다.</p>

<p><br /><br /></p>

<hr />

<h3 id="cupyzerosshape-dtype">cupy.zeros(shape, dtype)</h3>
<p>0으로 초기화한 cupy ndarray를 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupylinalgnormcupyndarray">cupy.linalg.norm(cupy.ndarray)</h3>
<hr />
<p>Euclidean norm(a.k.a L2 norm)한 결과를 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupycudadeviceintuse">cupy.cuda.Device(int).use()</h3>
<hr />
<p>cupy는 기본적으로 gpu 0을 사용하게 되어있습니다.
  이 명령어를 통해 원하는 gpu로 옮길 수 있습니다.</p>

<p><br /><br /></p>

<h3 id="cupyasnumpycupyndarray">cupy.asnumpy(cupy.ndarray)</h3>
<hr />
<p>앞서 잠깐 살펴보았던 .get()메서드와 같은 역할입니다.
  둘 중 원하는 방법으로 사용하셔도 무방합니다.</p>

<p><br /><br /></p>

<h3 id="cupyaddarray1-array2">cupy.add(array1, array2)</h3>
<hr />
<p>두 어레이의 원소별 덧셈을 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupysubtractarray1-array2">cupy.subtract(array1, array2)</h3>
<hr />
<p>두 어레이의 원소별 뺄셈을 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupymultiplyarray1-array2">cupy.multiply(array1, array2)</h3>
<hr />
<p>두 어레이의 원소별 곱셈을 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupydividearray1-array2">cupy.divide(array1, array2)</h3>
<hr />
<p>두 어레이의 원소별 나눗셈을 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupypowerarray1-array2">cupy.power(array1, array2)</h3>
<hr />
<p>두 어레이의 원소별 승곱을 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupymodarray1-array2">cupy.mod(array1, array2)</h3>
<hr />
<p>두 어레이의 원소별 나머지를 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupyabsolutearray">cupy.absolute(array)</h3>
<hr />
<p>어레이의 원소별 절대값을 취한 값을 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupyexparray">cupy.exp(array)</h3>
<hr />
<p>어레이의 원소별 Exponential 결과를 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupylogarray">cupy.log(array)</h3>
<hr />
<p>어레이의 원소별 log를 수행합니다.</p>

<p><br /><br /></p>

<h3 id="cupysqrtarray">cupy.sqrt(array)</h3>
<hr />
<p>어레이의 원소별 sqaure root 연산을 수행합니다.</p>

<p><br /><br /></p>

<h3 id="cupysquarearray">cupy.square(array)</h3>
<hr />
<p>어레이의 원소별 제곱연산을 수행합니다.</p>

<p><br /><br /></p>

<h3 id="cupysin-cupycos-cupytan">cupy.sin, cupy.cos, cupy.tan</h3>
<hr />
<p>다양한 삼각함수들도 지원하고 있습니다.</p>

<p><br /><br /></p>

<h3 id="cupyequalarray1-array2">cupy.equal(array1, array2)</h3>
<hr />
<p>두 어레이의 각 원소별로 값이 같은지 비교하여 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupymaximumarray1-array2">cupy.maximum(array1, array2)</h3>
<hr />
<p>두 어레이의 각 원소별로 큰 값을 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupyminimumarray1-array2">cupy.minimum(array1, array2)</h3>
<hr />
<p>두 어레이의 각 원소별로 작은 값을 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupyfloorarray">cupy.floor(array)</h3>
<hr />
<p>원소별 floor연산을 수행 후 반환합니다.</p>

<p><br /><br /></p>

<h3 id="cupyceilarray">cupy.ceil(array)</h3>
<hr />
<p>원소별 ceil연산을 수행 후 반환합니다.</p>

<p><br /><br /></p>

<h2 id="마치며">마치며</h2>
<hr />

<p>이것으로 오늘 과정을 마무리 하겠습니다.</p>

<p>오늘은 기초 부분이라 명령어의 연속이었습니다.</p>

<p>실은 cupy document를 참고 하셔도 무관합니다.</p>

<p>다음에는 cupy를 이용한 선형대수 표현에 대해서 이야기해보겠습니다.</p>

<p>질문 및 이야기는 언제든지 부탁드리겠습니다.</p>

<p>질문은 제가 활동하고 있는 사이트 Devstu에서 부탁드리겠습니다.</p>

<p><a href="https://devstu.co.kr">질문 하러 가기</a></p>]]></content><author><name>Jeyoung Lee</name></author><category term="RAPIDS" /><category term="Python" /><category term="Machine Learning" /><category term="DataScience" /><category term="Cupy" /><category term="cupy" /><category term="Data" /><category term="Data Science" /><summary type="html"><![CDATA[안녕하세요, 두번째 챕터 Cupy Part 01입니다.]]></summary></entry><entry><title type="html">01. RAPIDS Installation</title><link href="http://localhost:4000/Data-Science-With-RAPIDS-Install.html" rel="alternate" type="text/html" title="01. RAPIDS Installation" /><published>2020-08-02T22:00:00+09:00</published><updated>2020-08-02T22:00:00+09:00</updated><id>http://localhost:4000/Data-Science-With-RAPIDS-Install</id><content type="html" xml:base="http://localhost:4000/Data-Science-With-RAPIDS-Install.html"><![CDATA[<p><br /><br /></p>

<p>우선 첫번째 챕터 설치부터 살펴보겠습니다.</p>

<p>솔직히 설치 부분은 비교적 간단하기 때문에, 굳이 보시지 않으셔도 상관없습니다.</p>

<p>다만, 설치시에 문제가 있으시던가 하는 것을 방지하기 위하여 그리고 RAPIDS공식 홈페이지에 대해 알려드리기 위하여, 작성하였습니다.</p>

<p><br /><br /></p>

<h2 id="enviroment">Enviroment</h2>
<hr />
<p><br /><br /></p>

<p>제가 사용한 환경은 다음과 같습니다.</p>

<blockquote>
  <p>Ubuntu &gt;= 18.04 LST
<br />Anaconda
<br />Python &gt;= 3.6.8
<br />RAPIDS(stable) &gt;= 0.12
<br />CUDA &gt;= 10.0
<br />Cudnn &gt;= 7.6
<br />NUMPY &gt;= 1.16.1</p>
</blockquote>

<p><br /><br /></p>

<p>여러분들은 각자가 원하는 환경으로 구성하시면 됩니다.</p>

<p>다만, 이 칼럼에서는 저랑 비교적 똑같은 환경을 구축하시는것을 추천드립니다.</p>

<h2 id="rapids">RAPIDS</h2>
<hr />
<p><br /><br /></p>

<p><a href="https://rapids.ai/">RAPIDS</a></p>

<p>RAPIDS에 대한 대부분의 자료는 이곳에서 찾아보실 수 있습니다.</p>

<p>제가 작성하는 글은 이 사이트와, BLOG, SLACK, NVIDIA DLI등을 참고하여 작성하였습니다.</p>

<p><br /><br /></p>

<h2 id="installation">Installation</h2>
<hr />

<p><br /><br /></p>

<p>자, 그러면 설치를 시작해 볼까요?</p>

<p>RAPIDS 공식 사이트에 GET STARTED 버튼을 누르면, 설치 방법과, 설치할 수 있는 환경등을 설명해줍니다.</p>

<p>이번 칼럼에서는 아나콘다 환경에서의 설치 방법만 다루고 있습니다. 다른부분에 대해서는 다음 기회에 살펴보도록하겠습니다.</p>

<p>아나콘다에서는 어떻게 설치하는지 그림으로 먼저 살펴보겠습니다.</p>

<p><img src="./assets/img/images/RAPIDS/install/RAPIS_install.png" width="656" height="400" layout="responsive" alt="" class="mb3" /></p>

<p>순서대로 살펴 볼까요?</p>

<p>우선 가장 위에는 어떤 방법으로 설치할 것인지에 대한 부분입니다.</p>

<p>지금은 콘다환경에서 사용하기 때문에 콘다를 선택했습니다.(실은 제가 도커를 다루줄 잘 모르기때문에, 도커에 대한 부분은 도커 칼럼을 연재하면서 배워두려고합니다.)</p>

<p>그리고 Stable버젼과 Nightly버젼이 존재하는데, 우선 Stable버젼을 사용하도록하겠습니다.</p>

<p>마찬가지로 전 우분투 18.04를 사용하였으나, 실은 16.04와 18.04가 설치시에는 명령어 차이가 존재하지 않습니다.</p>

<p>그 다음은 파이썬 버젼에 대한 문제인데, 제 콘다 버젼은 파이썬 3.7까지 밖에 지원을 하지 않습니다.</p>

<p>그리고, 제가 실은 텐서플로 1버젼을 즐겨 사용했었기에 3.6버젼으로 선택했습니다. 이는 취향의 문제임으로 본인 취향껏 선택하시길 바라겠습니다.</p>

<p>마지막으로 CUDA버젼인데, 제가 사용하고 있는 노트북은 Geforce 1050을 사용하고 있습니다.</p>

<p>따라서 지원 여부를 잘 보고 선택해야하는데, 지금은 그나마 가장 안정화 버젼은 CUDA10.0을 선택했습니다.</p>

<p>(이 부분도, 어차피 콘다를 쓴다면 어떤 버젼을 사용하셔도 상관 없을 것으로 알고 있습니다.)</p>

<p>자 이제 선택이 모두 끝났습니다.</p>

<p>마지막으로 출력된 커맨드를 자신의 컴퓨터에 복사하여 사용하시면 됩니다.</p>

<p>모두 귀찮으실수도 있기에, 제 글에도 제 환경과 동일한 명령어 부분만 작성해 놓겠습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  conda <span class="nb">install</span> <span class="nt">-c</span> rapidsai <span class="nt">-c</span> nvidia <span class="nt">-c</span> conda-forge <span class="se">\</span>
    <span class="nt">-c</span> defaults <span class="nv">rapids</span><span class="o">=</span>0.14 <span class="nv">python</span><span class="o">=</span>3.6 <span class="nv">cudatoolkit</span><span class="o">=</span>10.1
</code></pre></div></div>

<p><br /><br /></p>

<h2 id="installation-check">Installation check</h2>
<hr />

<p><br /><br /></p>

<p>자 이제 마지막으로 성공적으로 설치되었는지 확인해볼까요?</p>

<p>간단한 명령어만 테스트 해보겠습니다.</p>

<p>저는 주피터 환경에서 테스트 하였습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kn">import</span> <span class="n">cupy</span> <span class="k">as</span> <span class="n">cp</span>
  <span class="kn">import</span> <span class="n">cudf</span> <span class="k">as</span> <span class="n">cd</span>
  <span class="kn">import</span> <span class="n">cuml</span> <span class="k">as</span> <span class="n">cm</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">X_cp</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">])</span>
  <span class="n">y_cp</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span><span class="mi">22</span><span class="p">,</span><span class="mi">33</span><span class="p">,</span><span class="mi">44</span><span class="p">,</span><span class="mi">53</span><span class="p">,</span><span class="mi">66</span><span class="p">,</span><span class="mi">77</span><span class="p">,</span><span class="mi">87</span><span class="p">,</span><span class="mi">95</span><span class="p">])</span>

  <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">X : </span><span class="sh">"</span><span class="p">,</span> <span class="n">X_cp</span><span class="p">)</span>

  <span class="err">!</span><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span>
</code></pre></div></div>

<p><img src="./assets/img/images/RAPIDS/install/Testing.png" width="656" height="400" layout="responsive" alt="" class="mb3" /></p>

<p>마지막으로 원본 코드 주소를 첨부하겠습니다.</p>

<p><a href="https://github.com/Ign0reLee/Data_Science_With_RAPIDS/blob/master/Chapter%2001.Installation/Testing_Installation.ipynb">원본코드 보러가기</a></p>

<p>깃허브에서 보시면 추가로 행렬간의 내적으로 시간을 측정한 부분도 포함되어있습니다.</p>

<p>이번챕터에서는 다루지 않았지만, 시간이 더 빨랐다 정도만 챙겨가시면 될 것 같습니다.</p>

<p>또한 질문 및 이야기는 언제든지 부탁드리겠습니다.</p>

<p>질문은 제가 활동하고 있는 사이트 Devstu에서 부탁드리겠습니다.</p>

<p><a href="https://devstu.co.kr">질문 하러 가기</a></p>

<p>감사합니다! 다음주에 뵙겠습니다.</p>]]></content><author><name>Jeyoung Lee</name></author><category term="RAPIDS" /><category term="Python" /><category term="Machine Learning" /><category term="DataScience" /><category term="Cupy" /><category term="Cudf" /><category term="CuML" /><category term="Data" /><category term="Data Science" /><summary type="html"><![CDATA[우선 첫번째 챕터 설치부터 살펴보겠습니다. 솔직히 설치 부분은 비교적 간단하기 때문에, 굳이 보시지 않으셔도 상관없습니다. 다만, 설치시에 문제가 있으시던가 하는 것을 방지하기 위하여 그리고 RAPIDS공식 홈페이지에 대해 알려드리기 위하여, 작성하였습니다. Enviroment 제가 사용한 환경은 다음과 같습니다. Ubuntu &gt;= 18.04 LST Anaconda Python &gt;= 3.6.8 RAPIDS(stable) &gt;= 0.12 CUDA &gt;= 10.0 Cudnn &gt;= 7.6 NUMPY &gt;= 1.16.1 여러분들은 각자가 원하는 환경으로 구성하시면 됩니다. 다만, 이 칼럼에서는 저랑 비교적 똑같은 환경을 구축하시는것을 추천드립니다.]]></summary></entry><entry><title type="html">00. Data Science With RAPIDS Introduction</title><link href="http://localhost:4000/Data-Science-With-RAPIDS-Intro.html" rel="alternate" type="text/html" title="00. Data Science With RAPIDS Introduction" /><published>2020-08-02T19:00:00+09:00</published><updated>2020-08-02T19:00:00+09:00</updated><id>http://localhost:4000/Data-Science-With-RAPIDS-Intro</id><content type="html" xml:base="http://localhost:4000/Data-Science-With-RAPIDS-Intro.html"><![CDATA[<p><br /><br />
  안녕하세요, 그리고 오랜만입니다.</p>

<p>기나긴 준비 시간이 끝나고, 드디어 새로운 칼럼을 연재하고자합니다.</p>

<p>과거 DLI Review를 진행하다가 RAPIDS와 처음 만났습니다.</p>

<p>그리고 RAPIDS는 제게 굉장히 큰 충격을 안겨주었습니다.</p>

<p>기존의 NUMPY와 PANDAS를 GPU에서 돌릴 수 있다.</p>

<p>매서드가 동일하여 이름만 바꾸면 된다.</p>

<p>이런 이야기들을 처음 그대로 들었을때는 별거 아니다 싶다가도 실제로 돌려보니 굉장히 개선되는 점이 많았습니다.</p>

<p>아직 RAPIDS는 우리나라에 제대로 소개하는 글이 없어서 아쉬웠습니다.</p>

<p>그래서 이번기회에 한글로 소개하고자합니다.</p>

<p>아직 학부생이기에 부족한 점도 많고, 제가 모르는 점도 많을 것 같습니다.</p>

<p>다만, GPU를 이용한 데이터 과학에 대해서 한번 생각해보시는 계기가 되셨으면합니다.</p>

<p><br /><br /></p>
<h2 id="enviroment">Enviroment</h2>
<hr />
<p><br /><br />
  아쉽지만, 이 칼럼에서는 환경을 조금 제한해야합니다.</p>

<p>공식적으로 지원되고 있는 환경이 넓지는 않습니다.</p>

<p>왠만하면 아래 환경을 따라가시기를 권장드립니다.</p>

<p>또한 리눅스를 사용하기 어려우신 분들은 콜랩환경을 권장드립니다.</p>

<p>다만, 콜랩 환경은 세션을 실행시킬 때 마다, RAPIDS를 새로 인스톨 해주어야합니다.</p>

<p>이와 관련해서는 다시 글을 작성하도록 하겠습니다.</p>

<p>Anaconda사용을 권장드립니다.</p>

<p>마지막으로 Ubuntu환경을 작성하기로는 18.04LST 이상이라고 적혀있으나, 제가 사용하는 버전 이상이라는 의미입니다.</p>

<p>또한, 하위 버전에서도 아마 가능할겁니다. 제가 아직 리눅스를 잘 다루지 못하여, 테스트를 할 수 없는점 죄송합니다.</p>

<blockquote>
  <p>Ubuntu &gt;= 18.04 LST
<br />Anaconda
<br />Python &gt;= 3.6.8
<br />RAPIDS(stable) &gt;= 0.12
<br />CUDA &gt;= 10.0
<br />Cudnn &gt;= 7.6
<br />NUMPY &gt;= 1.16.1</p>
</blockquote>

<p><br /><br /></p>

<h2 id="goal-of-this-column">Goal Of This Column</h2>
<hr />
<p><br /><br />
  이 칼럼의 목표에 대해 알려드리겠습니다.</p>

<p>우선 RAPIDS는 다음과 같이 구성되어 있습니다.</p>

<p><img src="./assets/img/images/RAPIDS/intro/RAPIDS_all.jpg" width="656" height="400" layout="responsive" alt="" class="mb3" /></p>

<p>이번 칼럼은 Data Science의 기초부분을 다루고자합니다.</p>

<p>따라서 딥러닝 부분에 대한 이야기는 나중에 따로 칼럼을 준비하겠습니다.</p>

<p>이 칼럼에서 알아보고자 하는 부분은 Numpy를 대체할 수 있는 Cupy,그리고 PANDAS를 대체할 수 있는 Cudf 마지막으로 scikit-learn을 대체할 수 있는 cuML부분입니다.</p>

<p>또한 각각의 예시를 CPU버젼, GPU버젼으로 시간을 비교하며 진행하도록 하겠습니다.</p>

<p><img src="./assets/img/images/RAPIDS/intro/RAPIDS_all_now.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
  <br /><br /></p>

<hr />

<p><br /><br />
  앞으로 일주일에 한번 연재하는 것이 목표입니다.</p>

<p>앞으로도 잘 부탁드리겠습니다. 감사합니다!</p>

<p>질문 및 이야기는 언제든지 부탁드리겠습니다.</p>

<p>질문은 제가 활동하고 있는 사이트 Devstu에서 부탁드리겠습니다.</p>

<p><a href="https://devstu.co.kr">질문 하러 가기</a></p>]]></content><author><name>Jeyoung Lee</name></author><category term="RAPIDS" /><category term="Python" /><category term="Machine Learning" /><category term="DataScience" /><category term="Cupy" /><category term="Cudf" /><category term="CuML" /><category term="Data" /><category term="Data Science" /><summary type="html"><![CDATA[안녕하세요, 그리고 오랜만입니다. 기나긴 준비 시간이 끝나고, 드디어 새로운 칼럼을 연재하고자합니다. 과거 DLI Review를 진행하다가 RAPIDS와 처음 만났습니다. 그리고 RAPIDS는 제게 굉장히 큰 충격을 안겨주었습니다. 기존의 NUMPY와 PANDAS를 GPU에서 돌릴 수 있다. 매서드가 동일하여 이름만 바꾸면 된다. 이런 이야기들을 처음 그대로 들었을때는 별거 아니다 싶다가도 실제로 돌려보니 굉장히 개선되는 점이 많았습니다. 아직 RAPIDS는 우리나라에 제대로 소개하는 글이 없어서 아쉬웠습니다. 그래서 이번기회에 한글로 소개하고자합니다. 아직 학부생이기에 부족한 점도 많고, 제가 모르는 점도 많을 것 같습니다. 다만, GPU를 이용한 데이터 과학에 대해서 한번 생각해보시는 계기가 되셨으면합니다. Enviroment 아쉽지만, 이 칼럼에서는 환경을 조금 제한해야합니다. 공식적으로 지원되고 있는 환경이 넓지는 않습니다. 왠만하면 아래 환경을 따라가시기를 권장드립니다. 또한 리눅스를 사용하기 어려우신 분들은 콜랩환경을 권장드립니다. 다만, 콜랩 환경은 세션을 실행시킬 때 마다, RAPIDS를 새로 인스톨 해주어야합니다. 이와 관련해서는 다시 글을 작성하도록 하겠습니다. Anaconda사용을 권장드립니다. 마지막으로 Ubuntu환경을 작성하기로는 18.04LST 이상이라고 적혀있으나, 제가 사용하는 버전 이상이라는 의미입니다. 또한, 하위 버전에서도 아마 가능할겁니다. 제가 아직 리눅스를 잘 다루지 못하여, 테스트를 할 수 없는점 죄송합니다. Ubuntu &gt;= 18.04 LST Anaconda Python &gt;= 3.6.8 RAPIDS(stable) &gt;= 0.12 CUDA &gt;= 10.0 Cudnn &gt;= 7.6 NUMPY &gt;= 1.16.1]]></summary></entry><entry><title type="html">Fundamentals Of Accelerated Data Science With RAPIDS</title><link href="http://localhost:4000/Nvidia-Accelerated-Data-Science-With-Rapids.html" rel="alternate" type="text/html" title="Fundamentals Of Accelerated Data Science With RAPIDS" /><published>2020-05-31T22:00:00+09:00</published><updated>2020-05-31T22:00:00+09:00</updated><id>http://localhost:4000/Nvidia-Accelerated-Data-Science-With-Rapids</id><content type="html" xml:base="http://localhost:4000/Nvidia-Accelerated-Data-Science-With-Rapids.html"><![CDATA[<p><br />
안녕하세요, NVIDIA DEEP LEARNING INSTITUTE REVIEW를 진행하고 있는 이제영입니다.</p>

<p><br /><br /> 다섯번째 시간입니다! 이번엔 Fundamentals Of Accelerated Data Science With RAPIDS Review로 돌아왔습니다!</p>

<p><br /><br /> 안타까운 소식이지만 아마 저희 스터디는 이번주로 마무리 지을 것 같습니다!, 기존에 친구들과 약속한 시간이 다 되었기 때문입니다.</p>

<p><br /><br /> 아참 그리고 이번주는 인증서와 관련한 헤프닝이 있었습니다.</p>

<p><br /><br /> 여러분들도 Accesment test시에 조심해주세요, 심사 숙고하신 후 제출해주시길 바라겠습니다!</p>

<p><br /><br /> RAPIDS는 Pandas, Numpy등과 유사한 점이 많았습니다!</p>

<p><br /><br /> 특히 Scikit-learn에 비해 편한 부분도 없잖아 있었습니다.</p>

<p><br /><br /> 그래서 그런지 이번주는 그림이 조금 많네요!</p>

<p><br /><br /> 블로그에 주기적으로 올리는 일은 앞으로 적어지겠지만 RAPIDS는 제가 개인적으로 마음에 들었기 때문에 종종 좋은 글이 보이면 해석해서 들고 오겠습니다!</p>

<p><br /><br /> 여러분도 한번 RAPIDS를 시작해보는 것이 어떠신가요?</p>

<p><br /><br /> 아무튼 이번주 리뷰 시작하도록하겠습니다!</p>

<hr />

<center>

<br /><h1>Review</h1>

<img src="./assets/img/images/DLI_RAPIDS/Review/1.png" width="656" height="400" layout="responsive" alt="" class="mb3" />

<h2>Index </h2><br />

<h4>-Summary</h4>

<h4>-Experience</h4>


</center>

<hr />

<p><br /></p>
<center>
<h2>Summary</h2>
<hr />

<br />
<h2>Introduction RAPIDS</h2>
</center>

<div style="text-align: left">

<ul>
<li>Course Goals</li><br />
	<ul>
	<li>일상적인 데이터 과학에 RAPIDS를 사용하는 핵심 도구에 대해 배우기</li><br />
	<li>워크 스테이션 및 클러스터에서 클라우드 및 HPC까지 RAPIDS의 확장성 이해하기</li><br />
	<li>계속해서 RAPIDS 기능을 배울 수 있는 기초 구축</li><br />
	</ul>
</ul>
<hr />
<br /><br /><img src="./assets/img/images/DLI_RAPIDS/Review/2.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; 전통적인 모델의 GPU 작동 순서도 &gt;
</center>

<br /><br /><img src="./assets/img/images/DLI_RAPIDS/Review/3.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; RAPIDS를 사용한 GPU 작동 순서도 &gt;
</center>

<div style="text-align: left">

<br /><br /> RAPIDS는 전통적인 모델과는 다르게, CPU와 GPU의 사이의 복사 변환 과정이 별도로 필요하지 않습니다.

<br /><br /> 따라서 전통적인 모델에 비해서 더 빠른 성능을 낼 수 있습니다.
</div>

<br /><br /><img src="./assets/img/images/DLI_RAPIDS/Review/4.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; RAPIDS의 구성 &gt;
</center>

<div style="text-align: left">

<br /><br /> RAPIDS는 다음과 같이 구성되어 있습니다.

<br /><br /> 이번 과정에서 우리는 CuDF와, CuML, CuGRAPH, CUXFILTER를 살펴보았습니다.

<br /><br /> 대부분의 경우 기존의 다른 툴들과 거의 흡사하다는 느낌을 받았습니다.

</div>

<br /><br /><img src="./assets/img/images/DLI_RAPIDS/Review/5.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; RAPIDS가 지원하는 데이터 과학용 툴 &gt;
</center>


<div style="text-align: left">

<br /><br /> RAPIDS에서 사용할 수 있는 데이터 툴들이 어떤 툴과 유사한 기능을 하는지 한눈에 살펴볼 수 있습니다.

<br /><br /> 이번 스터디에서의 경험상 대부분의경우 CPU를 사용하는 기존의 툴들보다 RAPIDS가 훨씬더 빠른 성능을 내었습니다.

</div>


<br /><br /><img src="./assets/img/images/DLI_RAPIDS/Review/6.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; RAPIDS의 공식 홈페이지 &gt;
</center>

<div style="text-align: left">

<br /><br /> 저희가 이 과정에서 배우는 것은 극히 일부일 뿐이며, 더 자세한 내용의 위의 공식 홈페이지에서 확인할 수 있었습니다.

<br /><br /> [공식 홈페이지 바로가기](https://rapids.ai/)

<br /><br /> 처음 보시는 분이라면 다소 불편할 수도 있습니다. 하지만 천천히 보시면 금방 익숙해 지실 수 있습니다.

</div>



<br /><br /><img src="./assets/img/images/DLI_RAPIDS/Review/7.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; CUDF의 설명 &gt;
</center>

<div style="text-align: left">

<br /><br /> CuDF란, RAPIDS에서 Data Handling을 담당하는 모듈로서, GPU 가속화된 dataframes를 만들고 조작하도록 돕습니다. 

<br /><br /> 또한 Pandas와 유사한 기능을 가지고 있습니다.


</div>

<br /><br /> <img src="./assets/img/images/DLI_RAPIDS/Review/8.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; RAPIDS로 연결할 수 있는 라이브러리들 &gt;
</center>

<div style="text-align: left">
<br /><br /> RAPIDS로 핸들링한 데이터들 혹은 RAPIDS를 사용하여 다른 패키지들과 상호 보완적으로 사용할 수 있습니다.

<br /><br /> RAPIDS에서 공식적으로 지원하는 팩들과 인터페이스를 가지고 있는것들이 표시되어 있습니다.
</div>


<br /><br /><img src="./assets/img/images/DLI_RAPIDS/Review/9.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; CuPY의 설명 &gt;
</center>

<div style="text-align: left">

<br /><br /> CuPy역시 Data Handling 툴입니다만, 주로 계산의 영역을 담당합니다.

<br /><br /> CPU에서 Numpy와 같은 역할을 담당합니다.

<br /><br /> 사용 방법 역시 유사합니다.

</div>

<br /><br /><img src="./assets/img/images/DLI_RAPIDS/Review/10.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; CUGRAPH의 설명 &gt;
</center>

<div style="text-align: left">

<br /><br /> CuGRAPH는 Graph를 연구하기위한 NetworkX와 거의 유사합니다.

<br /><br /> NetworkX를 제가 사용해보지 않아서 용법이 유사한 것 까지는 모르겠습니다.

<br /><br /> 하지만 CUGRAPH를 활용하여 그래프를 분석하고, xFilter등을 활용하여 Visualize를 진행합니다.

<br /><br /> 그리고 다음의 용어를 배웠습니다.

<br /><br />  unique() – 값

<br /><br />  Str.lstrip(‘#’) – 제거

<br /><br />  Factorize() – 라벨링

<br /><br />  Dask – 병렬 컴퓨팅

</div>

<br /><br /><img src="./assets/img/images/DLI_RAPIDS/Review/11.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; RAPIDS에서 지원하는 TASK SCHEDULER 모형 &gt;
</center>

<div style="text-align: left">

<br /><br /> 또한 다양한 Operation의 SCHEDULER를 제공합니다.

</div>

<br /><br /><img src="./assets/img/images/DLI_RAPIDS/Review/12.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<center>
&lt; CuML의 설명 &gt;
</center>
<div style="text-align: left">

<br /><br /> 마지막으로 CuML입니다.

<br /><br /> 저는 개인적으로 Scikit-learn과 유사하다는 느낌을 많이 받았습니다.

<br /><br /> 이번 과정에서는 위에 보이는 5개의 알고리즘을 CuML를 사용하여 다루어 보았습니다.

<br /><br /> 솔직히 다루는 방법보다는 데이터가 어떻게 생겼는지를 더 많이 살펴본 것 같습니다.

<br /><br /> 

</div>
<br />
<hr />
<br />


<center>
<h2>Experience</h2>
</center>
<hr />
<br />
<center> 
<br /><br />
<center> 
<h4>Experience-이제영</h4>
</center>
<div style="text-align: left">
<br /><br /> RAPIDS는 굉장히 좋은 것 같다.

<br /><br /> 솔직히 Numpy, Numba, Pandas, Scikit-learn등을 따로 배우는 것 보다 편하고 좋은 것 같다.

<br /><br /> 과정 자체도 만족스럽다.

<br /><br /> 누구에게나 추천한다.

<br /><br /> 데이터 사이언스를 배우고 싶으면 비추천한다.

<br /><br /> RAPIDS의 Document가 생각보다 불편하게 되어 있는데, 이 과정을 수강하면 매우 도움이 될 것이다.

<br /><br /> 아직 RAPIDS가 완성이 아닌 것 같아 앞으로의 버전이 매우 기대가 된다.

<br /><br />
<hr />
<br /><br />
<center> 
<h4>Experience-박경훈</h4>
</center>
<div style="text-align: left">
<br /><br /> CPU와 GPU의 속도차이를 결과로 확인할 수 있어서 좋았다.

<br /><br /> Pandas와 상당히 유사하기 때문에 접근하기 쉬웠다.

<br /><br /> 개인적으로 강의가 루즈해서 별로였다.
<br /><br />
<hr />
<br /><br />
<center>
<h4>Experience-구정수</h4>
</center>
<div style="text-align: left">

<br /><br /> GPU를 사용하여 데이터 분석을 빠르게 수행할 수 있었다.

<br /><br /> CPU만을 사용하는 경우와 비교해서 속도 차이가 컸다.

<br /><br /> Pandas, Numpy와 많은 부분에서 유사해서 기존의 데이터 과학을 배운 사람들이 손쉽게 사용할 수 있을 것이라 생각한다.

<br /><br /> Jupyter Lab 환경이 매우 편리했다.
<hr />

<center>
<h2>인증서</h2>
</center>
<hr />
<img src="./assets/img/images/DLI_RAPIDS/In/박경훈.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<br />
<img src="./assets/img/images/DLI_RAPIDS/In/이제영.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<br />
<img src="./assets/img/images/DLI_RAPIDS/In/구정수.png" width="656" height="400" layout="responsive" alt="" class="mb3" />

<br /><br />
<hr />

<br /><br /> 긴 글 읽어주셔서 감사합니다! 이번 과정은 배우는 내용보단 RAPIDS를 배운다는 느낌이 강합니다!

<br /><br /> 저는 매우 만족했던 과정이었던 것 같습니다. 특히 다들, Accesment에서 굉장히 헤매더라고요...

<br /><br /> 혹시 이 과정에 대해 관심 있으시면, 저희의 리뷰를 참고하시면 좋을 것 같습니다.

<br /><br /> 거듭 말씀드리지만 리뷰는 저희들의 개인적인 의견이며, 실제 과정에서는 위의 내용들과 더불어 코딩하시면서 배우실 수 있습니다!

<br /><br /> 한달동안 고생 많이 하셨습니다! 저희 DLI Review 스터디는 이로써 막을 내리지만, DLI 과정은 꾸준하게 열리고, 업데이트 되고 있습니다.

<br /><br /> 시작하기 앞서서, 어떤 과정인지 간단히 살펴보고 어떤느낌인가 정도를 보실때 참고가 되셨으면 좋겠습니다!

<br /><br /> 또한 궁금한점이 있으시면 언제든지 메일 바라겠습니다. 기다리고 있겠습니다.

<hr />
<hr />

<br /><br /> 마지막으로 홍보 하나만 하겠습니다!

<br /><br /> NVIDIA 는 AI 스타트업의 비즈니스/기술 개발에 필요한 여러 자원들을 지원해주는 인큐베이팅 프로그램을 운영하고 있고 전세계적으로 약 5,800 개의 스타트업들과 협력 노력을 하고 있습니다!

<br /><br /> 이 프로그램의 일환으로 실제 AI 기술을 적용하는 AI 스타트업에게 실질적인 지원을 해주고자 중소벤처기업부와 함께 N&amp;UP 프로그램을 진행한다고 합니다!

<br /><br /> NVIDIA 엔지니어 분들이 심사위원으로 참여하며 무려 사업 지원비 최대 3억, 뽑힌 30개의 기업들끼리 추가 심사를 통해 R&amp;D 투자비 최대 4억을 지원해주는 프로그램이라고 합니다!

<br /><br /> 자세한 내용은 링크 남기도록 하겠습니다!

<br /><br />[온라인 세미나](https://youtu.be/L717kWEmgbY)

<br /><br />[모바일에서 자세히 보기](http://me2.do/FTnFsv66)

<br /><br />[PC에서 자세히 보기](http://me2.do/FoAMy5jr)

<br /><br /> 감사합니다! 다음번에 다른 포스트로 다시 찾아뵙겠습니다!
</div>
</div></div></center></div>]]></content><author><name>Jeyoung Lee</name></author><category term="Nvidia Deep Learning Institute" /><category term="Review" /><category term="DLI" /><category term="Data Science" /><category term="RAPIDS" /><category term="Python" /><category term="Deep Learning" /><category term="Machine Learning" /><summary type="html"><![CDATA[안녕하세요, NVIDIA DEEP LEARNING INSTITUTE REVIEW를 진행하고 있는 이제영입니다.]]></summary></entry><entry><title type="html">Fundamentals of Accelerated Computing with CUDA Python Review</title><link href="http://localhost:4000/Nvidia-DLI-CUDA-WITH-Python.html" rel="alternate" type="text/html" title="Fundamentals of Accelerated Computing with CUDA Python Review" /><published>2020-05-24T22:00:00+09:00</published><updated>2020-05-24T22:00:00+09:00</updated><id>http://localhost:4000/Nvidia-DLI-CUDA-WITH-Python</id><content type="html" xml:base="http://localhost:4000/Nvidia-DLI-CUDA-WITH-Python.html"><![CDATA[<p><br />
안녕하세요, NVIDIA DEEP LEARNING INSTITUTE REVIEW를 진행하고 있는 이제영입니다.</p>

<p><br />네번째 시간입니다! 이번엔 Fundamentals of Accelerated Computing with CUDA Python Review로 돌아왔습니다!</p>

<p><br />이번주는 그 전에 진행했던 Fundamentals of Accelerated Computing with CUDA C/C++ 과 비슷하다는 느낌을 많이 받았다고 하는데요</p>

<p><br />내용 자체는 그 전과 크게 다르지 않으나 학기를 다니다보니 아무래도 조금 씩 늦어집니다.</p>

<p><br />앞으로도 시간을 잘 지킬 수 있도록 노력하겠습니다!</p>

<p><br />많이 부족하지만 앞으로도 잘 부탁드리겠습니다.</p>

<p><br />질문있으시면 언제든지 메일을 보내주세요! 기다리고 있겠습니다.</p>

<hr />

<center>

<br /><h1>Review</h1>

<img src="./assets/img/images/DLI_Python/Review/1.png" width="656" height="400" layout="responsive" alt="" class="mb3" />

<h2>Index </h2><br />

<h4>-Summary</h4>

<h4>-Experience</h4>


</center>

<hr />

<p><br /></p>
<center>
<h2>Summary</h2>
<hr />

<br />
<h2>Introduction to CUDA Python with Numba</h2>
</center>

<div style="text-align: left">

<ul>
<li>이번 챕터의 목표</li><br />
	<ul>
	<li>Numba를 활용하여 CPU에서 Python function들을 Compile 할 수 있습니다.</li><br />
	<li>Numba가 어떻게 Python Function들을 compile 하는지 알 수 있습니다.</li><br />
	<li>NumPy ufuncs GPU 가속화 할 수 있습니다.</li><br />
	<li>hand-written vectorized functions GPU 가속화 할 수 있습니다.</li><br />
	<li>CPU host와 GPU device간의 데이터 전송을 최적화 할 수 있습니다</li><br />
	</ul>
</ul>


<ul>
<li>Numba란 무엇인가?</li><br />
	<ul>
	<li>Numba는 CPU 또는 GPU환경에서 numerically-focused Python을 가속화 하기 위한 just-in-time, type-specializing, function compiler입니다.</li><br />
		<ul>
		<li>function compiler</li><br />
			<ul>
			<li>Numba는 파이썬 함수를 컴파일합니다.</li><br />
			<li>어플리케이션 전체를 컴파일하지 않습니다.</li><br />
			<li>Numba는 파이썬 인터프리터를 대체하지 않습니다.</li><br />
			<li>단지 기존의 함수를 더 빠른 함수로 대체하는 파이썬 모듈일 뿐입니다.</li><br />
			</ul>
		<li>type-specializing</li><br />
			<ul>
			<li>Numba는 특수한 데이터 타입에 대해 특별한 구현을 생성하면서 함수를 빠르게 합니다.</li><br />
			<li>파이썬 함수는 보편적인 데이터 타입에서 작동하도록 설계되어있습니다.</li><br />
			<li>이는 매우 유연하지만 느립니다.</li><br />			
			</ul>
		<li>just-in-time</li><br />
			<ul>
			<li>Numba는 처음 선언되면 함수를 번역합니다.</li><br />
			<li>어떤 변수 자료형이 사용될 지 알아야합니다.</li><br />
			<li>기존 어플리케이션과 마찬가지로 Jupyter 노트북에서 대화식으로 사용할 수 있습니다.</li><br />
			</ul>
		<li>numerically-focused</li><br />
			<ul>
			<li>일반적으로 Numba는 Numerical Data 타입에 맞춰져 있습니다.</li><br />
			<li>그러므로 String형 데이터에 매우 제한적이고, 많은 String형 사용사례가 GPU에서 작동하지 않습니다.</li><br />
			<li>Numba에서 좋은 결과를 얻으려면 Numpy 배열을 사용해야합니다.</li><br />
			</ul>
		</ul>
	</ul>
</ul>
</div>
<hr />

<p><br /></p>

<center>
<h4>How Numba Works</h4>
</center>
<p><br /><br /><img src="./assets/img/images/DLI_Python/Review/2.png" width="656" height="400" layout="responsive" alt="" class="mb3" /></p>
<center>
&lt; Numba의 작동 순서도 &gt;
</center>
<div style="text-align: left">
<br /><br /> Numba 컴파일러는 function decorator를 사용하여 활성화할 수 있습니다.
<br /><br /> Decorators는 함수를 변형합니다.
<br /><br /> Numba에서의 CPU compilation decorator는 @jit입니다.

<br /><br />.py_func attribute를 통해 original python function을 호출할 수 있습니다.

<br /><br /> @vectorize detorator를 사용하여 compiled ufuncs를 만들 수 있습니다.
<br /><br /> 특정 자료형을 지정하여 CUDA GPU에서 실행되도록 선언할 수 있습니다.

<br /><br />GPU가 CPU보다 느린 경우, 아래의 상황인지 살펴봅시다.
<ul>
<li>입력값이 너무 작은 경우</li><br />
<li>계산이 너무 간단한 경우</li><br />
<li>GPU로 데이터를 복사하거나 읽어들일 경우</li><br />
<li>자료형이 필요 이상으로 클 경우</li><br />
</ul>

<br /><br />CUDA Device Arrays를 사용하여 GPU 내에 데이터를 저장할 수 있습니다.

</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h2>Custom Kernels and Memory Management for CUDA Python with Numba</h2>
</center>
<div style="text-align: left">

<ul>
<li>이번 챕터의 목표</li><br />
	<ul>
	<li> Python으로 커스텀 CUDA커널을 작성하고 실행합니다.</li><br />
	<li>Grid Stride Loops를 활용하여 대규모 DataSet에서 병렬로 작업하고 메모리를 통합 활용할 수 있습니다.</li><br />
	<li>atomic operations를 사용하여 병렬 작업시 race conditions를 회피합니다/</li><br />
	</ul>
</ul>
</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h4>The Need for Custom Kernels</h4>
</center>
<div style="text-align: left">

<br /><br /> GPU에서 가속화되는 ufuncs를 사용하는 것 보다 더욱 힘든 일입니다. 

<br /><br /> custom CUDA kernels를 작성하는 것은 개발자에게 functions의 types에 대해 엄청난 유연성을 제공합니다.
</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h4>Introduction to CUDA Kernels</h4>
</center>
<div style="text-align: left">
<br />

<br /><br /> CUDA로 프로그래밍 할 때 개발자는 병렬 커널 스레드의 GPU의 많은 코어에서 실행 되거나 CUDA 용어로 실행되는 커널이라는 GPU에 대한 함수를 작성합니다.

<br /><br /> 커널이 시작될 때 프로그래머는 "Excution Configuration"이라는 특수 구문을 사용하여 병렬 실행 구성을 설명합니다.

</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h4>CUDA Thread Hierarchy</h4>
</center>
<div style="text-align: left">
<br />

<br /><br /> GPU에서 함수를 실행할 때 어떤 일이 일어나는지 알아봅시다.

<br /><br />  GPU는 병렬로 작업을 수행합니다.

<br /><br />  이러한 작업은 thread에서 수행됩니다.

<br /><br />  여러 threads가 병렬로 동작한다. CUDA는 수 천개의 threads를 병렬로 처리할 수 있습니다.

<br /><br />  threads의 집합을 block이라 한다. 여러 개의 block이 존재할 수 있습니다.

<br /><br />  주어진 커널 실행에 대한 blocks의 집합을 grid라고 한다. GPU 함수를 kernel이라 부릅니다.

<br /><br />  kernels는 execution configuration과 함께 실행됩니다.

<br /><br />  execution configuration은 grid 안의 blocks의 수, 각 blocks의 threads의 수를 정의합니다.

<br /><br />  한 grid 안의 모든 block은 같은 수의 threads를 가집니다.

<br /><br /> grid &gt; block &gt; thread

</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h4>CUDA-Provided Thread Hierarchy Variables</h4>
</center>
<div style="text-align: left">
<br />

<br /><br /> gridDim.x 는 grid 안의 blocks의 수입니다.

<br /><br /> blockIdx.x 는 grid 안의 현재 block의 index입니다.

<br /><br /> blockDim.x 는 block 안의 threads의 수입니다.

<br /><br /> threadIdx.x 는 block 안의 thread의 index입니다.


</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h4>An Aside on Hiding Latency and Execution Configuration Choices</h4>
</center>
<div style="text-align: left">
<br />

<br /><br /> CUDA 지원 NVIDIA GPU는 DRAM에 연결된 여러 개의 Streaming Multiprocessors 또는 SMs on a die로 구성됩니다.
<br /><br /> SM에는 많은 CUDA 코어를 포함한 커널 코드 실행에 필요한 모든 리소스가 포함되어 있습니다.
<br /><br /> 커널이 시작되면 각 블록은 단일 SM에 할당되고 잠재적으로 많은 블록이 단일 SM에 할당됩니다.
<br /><br /> SM은 블록을 "워프 (warps)"라고하는 32 개의 스레드로 세분화하고 실행하기 위해 병렬 명령이 제공되는 워프입니다.

<br /><br /> 따라서 GPU의 모든 잠재력을 활용하여 성능이 향상된 응용 프로그램을 작성하는 것이 가장 중요하기 때문에 SM이 커널을 실행하여 가장 간단하게 달성 할 수있는 충분한 수의 왜곡을 제공함으로써 대기 시간을 숨길 수있는 기능을 제공해야합니다.
<br /><br /> 그리드 및 블록 치수가 충분히 커야합니다.

</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h4>Atomic Operations and Avoiding Race Conditions</h4>
</center>
<div style="text-align: left">
<br />

<br /><br />다른 병렬 처리 프레임워크와 마찬가지로, CUDA 또한 race condition(경쟁 상태)가 발생할 수 있습니다

<ul>
		<li>read-after-write hazards</li><br />
			<ul>
			<li>한 스레드가 다른 스레드가 쓰는 동안 메모리 위치를 읽는 중입니다.</li><br />
			</ul>
		<li>write-after-write hazards</li><br />
			<ul>
			<li>두 개의 스레드가 동일한 메모리 위치에 쓰고 있으며 커널이 완료되면 하나의 쓰기 만 표시됩니다.</li><br />		
			</ul>
</ul>
<br /><br /> 이러한 문제를 피하려면 CUDA kernel algorithm을 잘 짜야 합니다.

<br /><br /> CUDA는 atomic operations를 제공합니다.

<br /><br /> 이를 활용하여 잘 피해갈 수 있습니다.

</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h2>Multidimensional Grids and Shared Memory for CUDA Python with Numba</h2>
</center>
<div style="text-align: left">
<ul>
<li>이번 챕터의 목표</li><br />
	<ul>
	<li>다차원 블록 및 그리드를 사용하여 다차원 데이터 세트에서 GPU 가속 병렬 작업을 수행합니다.</li><br />
	<li>공유 메모리를 사용하여 데이터를 칩에 캐시하고 느린 글로벌 메모리 액세스를 줄입니다.</li><br />
	</ul>
</ul>
</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h4>2 and 3 Dimensional Blocks and Grids</h4>
</center>
<div style="text-align: left">

<br /><br /> blocks = 4					=&gt;	blocks = (2, 2)

<br /><br /> threads_per_block = 4		=&gt;	threads_per_block = (2, 2)

</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h4>2 and 3 Dimensional Blocks and Grids</h4>
</center>
<div style="text-align: left">

<br /><br /> grid = cuda.grid(1)				=&gt;	grid_y, grid_x = cuda.grid(2)

<br /><br /> stride= cuda.gridsize(1)			=&gt;	stride_y, stride_x = cuda.gridsize(2)

</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h4>Shared Memory</h4>
</center>
<div style="text-align: left">

<br /><br /> Nunba는 blocks 간의 threads 사이의 shared memory를 할당할 수 있습니다.

<br /><br /> 병렬 threads 읽기나 쓰기에서 shared memory는 필수입니다.

<br /><br /> Shared memory를 선언할 때 shared memory의 크기를 설정해야 합니다.

<br /><br />  이 크기는 정적인 값입니다. 

<br /><br />  temp = cuda.shared.array(4, dtype=types.int32)

<br /><br />  idx = cuda.grid(1)

</div>
<p><br /></p>
<hr />

<p><br /></p>

<center>
<h2>Experience</h2>
</center>
<hr />

<p><br /></p>
<center> 
<h4>Experience-구정수</h4>
</center>
<hr />

<p><br /><br /></p>
<center> 
<h4>Experience-이제영</h4>
</center>
<div style="text-align: left">
<br /><br />NUMBA가 C++보다 편했습니다.

<br /><br />다만 가독성이 C++보다 살짝 떨어지는 것 같다.

<br /><br />총속도가 얼마나 빠르진 감이 안 잡힌다.

<br /><br />C++은 못하겠고, CUDA는 해보고 싶으면 추천합니다.

<br /><br />CUDA만 해보고싶으면 차라리 C++로 가는게 좋을 것 같다.
</div>
<p><br /><br /></p>
<hr />

<p><br /><br /></p>
<center> 
<h4>Experience-박경훈</h4>
</center>
<div style="text-align: left">
<br /><br />NUMBA의 사용법을 간략하게 알 수 있다.

<br /><br />C/C++ 가속화 컴퓨팅과 공통되는 부분이기 때문에 한 과정만 들어도 괜찮지만, C++ 과정이 좀 더 좋았다.

<br /><br />시험이 어려웠다.

<br /><br />Python을 다루는 분들에게 추천한다.

<h4>Experience-구정수</h4>
&lt;/center&gt;
<div style="text-align: left">
<br /><br />Python으로 GPU에서 동작하는 CUDA 명령어를 사용할 수 있다는 사실이 흥미로웠다.

<br /><br />병렬 처리를 통해 기존의 연산보다 빠른 속도를 낼 수 있었다. 

<br /><br />주어진 문제에 대한 설명이 좀 더 자세했으면 좋았을 것 같다. 

<br /><br />Python 문법을 잘 알고 있는 사람에게 추천할 만하다.

<hr />

<center>
<h2>인증서</h2>
</center>
<hr />
<img src="./assets/img/images/DLI_Python/In/박경훈.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<br />
<img src="./assets/img/images/DLI_Python/In/이제영.png" width="656" height="400" layout="responsive" alt="" class="mb3" />
<br />
<img src="./assets/img/images/DLI_Python/In/구정수.png" width="656" height="400" layout="responsive" alt="" class="mb3" />

<br /><br />
<hr />

<br /><br />긴 글 읽어주셔서 감사합니다! C++때 겹치는 부분이 많아 block, thread등의 그림은 첨부하지 않았습니다!

<br /><br />또 저희 친구들은 c++를 더 선호하는 경향이 있네요, 둘다 좋은 강의입니다!

<br /><br />마찬가지로 모든 리뷰는 주관적이라는점 알아주시면 감사하겠습니다!

<br /><br />앞으로 저희의 리뷰를 통해 Nvidia에서 열리는 DLI 프로그램에 대해 궁금하신점을 해결해가셨으면 좋겠습니다!

<br /><br />이렇게만 보시면 감이 안잡히실 수도 있지만! 실제로 DLI프로그램을 진행하면 직접 코딩하시면서 하실 수 있습니다.

<br /><br />이런 것들을 배우는 구나~ 가 더 중요하게 보셔야할 점인 것같습니다.

<br /><br />다음주에는 Fundamentals of Accelerated Data Science with RAPIDS리뷰로 돌아오겠습니다! 감사합니다!
</div>
</div>]]></content><author><name>Jeyoung Lee</name></author><category term="Nvidia Deep Learning Institute" /><category term="Review" /><category term="DLI" /><category term="CUDA" /><category term="Numba" /><category term="Python" /><category term="Deep Learning" /><category term="Machine Learning" /><summary type="html"><![CDATA[안녕하세요, NVIDIA DEEP LEARNING INSTITUTE REVIEW를 진행하고 있는 이제영입니다.]]></summary></entry></feed>